\section {Staged Programming in \lang}
\label{sec:staging}

\begin{figure*}
\label{fig:quickselect}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting} 
datatype list = Empty | Cons of int * list
fun partition (p : int, l : list) 
  : (int*list*list) =
  case unroll l of 
    Empty => (0,Empty, Empty) 
  | Cons (h,t) =>
      let (s,left,right) = partition (p,t) in
      if h<p 
      then (s+1,Cons(h,left),right)
      else (s,left,Cons(h,right))

fun qs (l : list, k : int) : int = 
  case l of
    Empty => 0
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
        case compare k n of
          LT => qs (left, k)
        | EQ => h
        | GT => qs (right, k-n-1)
\end{lstlisting}
\caption{Unstaged implementation of quickselect.}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting} 
datatype list = Empty | Cons of int * list
fun partition (p : int, l : list) = ...

fun qs (l : list, k : $int) : $int = 
  case l of
    1`Empty` => next {2`0`}
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
      next{
        let n = hold{n} in
          case compare prev{k} n of
            LT => prev {qs (left k)}
          | EQ => hold {h}
          | GT => prev {qs (right, next{prev{k}-n-1)}}
      }	
\end{lstlisting}
\caption{Staged implementation of quickselect in \lang.}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}
datatype list = Empty | Cons of int * list
fun partition (p : int, l : list) = ...
	
datatype tree = Branch of int * int * tree * tree
                | Leaf

fun qs1 (l : list) : tree =
  case l of
    Empty => Leaf
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
      Branch (n, h, qs1 left, qs1 right)

fun qs2 (p : tree, k : int) : int = 
  case unroll p of
    Leaf => 0
  | Branch (n,h,p1,p2) => 
      case compare k n of
        LT => qs2 (p1,k)
      | EQ => h
      | GT => qs2 (p2,k-n-1)
\end{lstlisting}
\caption{Split (two-phase) implementation of quickselect.}
\end{minipage}
\caption{Caption place holder}
\end{figure*}

As an example of an algorithm amenable to staging techniques,
consider the quickselect algorithm shown in Figure~2a.
Quickselect is an $O(n)$ (expected time) algorithm for finding the $k$-th largest element in a randomly ordered length-$n$ list.
It does so by partitioning the input list into sublists containing elements less than and greater than the head element, 
then recursing on the sublist containing the desired element.

Importantly, one property of quickselect is that the partitioning of the list, even across recursive calls, depends only on the values of list elements, not on the value of $k$ 
\footnote{There is a control-dependence on $k$ -- that is $k$ determines what splits are made but not how they are made -- we ignore this for now.}.  This independence allows the quickselect algorithm to be split into two functions:
one which precomputes all partitions of the input list (to construct a binary search tree---see \texttt{qs1} in Figure~2c),
and another which uses this tree to perform an accelerated lookup of the $k$-th element (essentially performing binary search of a sorted list---see \texttt{qs2}).
One advantage of splitting the algorithm into two phases is that the search tree can be constructed for a list once
and then used to accelerate many future lookups for any value of $k$.

This paper defines how to statically perform splitting transformations, like the one described above, on programs written in a simple staged language we call \lang.  \lang clearly and unambiguously specifies how its terms should be split
% and features a type system that ensures valid splittings exist.
% only minimal refactoring should be required to write terms within this language,
%and from there, the type system should be enough to prove that a valid splitting exists.
by identifying each term with one of two {\em stages}, namely \bbone\ or \bbtwo.
Intuitively, the stage of a \lang\ term expresses \emph{when} to evaluate it---all stage-\bbone\
subexpressions are evaluated before stage-\bbtwo\ ones.  After splitting, those parts of the \lang\ term in stage \bbone\ will end up in the precomputation, 
and those parts in stage \bbtwo\ will end up in the residual.
Within well-typed terms, information can flow from stage \bbone\ to stage \bbtwo\ portions,
but never from \bbtwo\ to \bbone.  
Indeed this is a necessary property if we want to be able to split the term.

Figure 2b shows a staged implementation of quickselect in \lang.
As before, the function accepts as input the list to select from and a value of $k$,
but now the latter is represented with the type $\fut\rmint$ rather than $\rmint$.
The difference here is that an $\rmint$ is an integer available at the current stage (stage \bbone), 
whereas a $\fut\rmint$ is an integer available only at the next stage (stage \bbtwo).
Naturally the output type, representing the $k$th largest element of the list,
is also $\fut\rmint$, since it is not computed until stage \bbtwo.

Each construct in the body of quickselect is now associated with a stage via an interleaving of $\next$ and $\prev$ blocks.  
Specifically, $\next$ occurs in a stage \bbone\ context and indicates that the contents of its block are stage \bbtwo, 
whereas $\prev$ occurs in a stage \bbtwo\ context and indicates that the contents of its block is stage \bbone.
(We adapt the convention that the top-level context is stage \bbone.)
The output type of a $\next$ block is the $\fut$'d version of the type of its stage \bbtwo\ contents.  
For example, \verb|next{0}| from above has the type $\fut\rmint$.
Correspondingly, $\prev$ requires that its stage \bbone\ contents have a $\fut$ type, and it eliminates the wrapper.
For example, \verb|prev{k}| from above has type $\rmint$ at stage \bbtwo, since $k$ is bound to a $\fut\rmint$ at stage \bbone.
These type restrictions essentially enforce that ``later stage content" is always treated hygienically at stage \bbone,
which is necessary to admit a properly staged implementation.

The code also contains two $\pause$ blocks.  
This construct has same stage signature as $\prev$,
but instead of ``unwrapping" $\fut$ types it simply promotes integers from stage~\bbone\ to stage~\bbtwo.
\footnote{It will turn out that $\pause$ is implementable---though it takes some effort---from our other language features.
We instead provide it as a primitive to shorten examples.  
Furthermore, it would be wise to extend $\pause$ to other base types, if we had them, and to products and sums thereof.
This is related to the notion of {\em mobility} in \cite{murphy05} and {\em stability} in \cite{krishnaswami13}.}

But for the $\fut$, $\next$, $\prev$, and $\pause$ constructs, 
the staged version of quickselect in Figure~2b is virtually identical to the unstaged version in Figure~2a.
The constructs that were added were placed in order to maximize the work done at stage~\bbone\ while still conforming to the type signature.
It would have also been valid to simply move the whole input list unchanged into stage~\bbtwo\ at the very beginning, 
but that would not be particularly interesting since it would result in an effectively trivial split 
that's just the identity at stage~\bbone\ and plus quickselect at stage~\bbtwo.
There has been the extensive research into the question of how to automatically add staging annotations to unstaged code.
This process is known as {\em binding time analysis}, and we do not consider it here.
Instead, we assume that all input programs are properly staged according to some programmer's intent.

\section{\lang\ Statics and Dynamics}
\label{sec:semantics}

\input {figures/grammars}
\input {figures/statics}

As stated in \cref{sec:staging}, in this paper we describe splitting in the context of \lang,
a typed two-stage lambda calculus featuring products, sums, and isorecursive types.
The grammar (\cref{fig:grammar}) and type system of \lang\ are an adaptation of those of \cite{davies96}, 
restricted to two stages and extended with general sums and recursion\footnote{This restriction to two stages is made primarily for 
simplicity of presentation.  All of these techniques could feasibly be extended to more
complicated stage systems.}.  The following subsections provide a brief overview of the type system for \lang, and highlight important differences in its semantics from this prior work.

\subsection{Statics}

In \lang, the $\fut$ constructor encapsulates a stage \bbtwo\ type at stage~\bbone.  
But because of the two-stage assumption, $\fut$ has no meaning when used at stage~\bbtwo.
This restriction is managed by the type validity judgment, whose rules are given in \cref{fig:validTypes}. 
In short, $\Delta \vdash A \istypewor$ means that type $A$ is valid at world $w$ under the assumptions in $\Delta$.
This context is only augmented by recursive types.

The typing judgment, like type validity, is annotated with a stage.
Thus we can read $\typeswor x A$ as saying that term $x$ has type $A$ at world $w$ under the context $\Gamma$.
The typing rules are given in \cref{fig:statics}.
The staging features ($\next$, $\prev$, and $\pause$) behave as described in the previous section,
and all other features behavior in the standard way and are essentially agnostic to stage. 
Variables in the context are annotated with the stage at which they were introduced 
and can only be used at the same stage.
As one would expect, the typing judgment only produces well-formed types 
(by induction on the derivation of the typing judgment).

\subsection{Dynamics}
\label{sec:stagedsemantics}

A key attribute of the quickselect example is that stage-\bbone\ and stage-\bbtwo\ expressions are nested. 
Ordinary term evaluation eliminates outermost redexes first, 
however in the case that stage \bbone\ expressions are contained inside stage~\bbtwo\ ones 
(such as the recurive call to {\tt fexp} above), 
this strategy conflicts with the precept of staged execution: 
that all stage-\bbone\ code be evaluated before the evaluation of stage-\bbtwo\ code. 

Thus, our dynamic semantics for \lang\ evaluates all of a term's stage \bbone\
subexpressions before any of its stage~\bbtwo\ subexpressions. This results in a
stage \bbtwo\ term with no stage~\bbone\ content; we say this is a term in a
monostaged language called \langTwo. Then, we perform the remainder of the evaluation with 
$\tworedsym$, an ordinary dynamic semantics for \langTwo\ (the rules for this
judgment are not shown, but they are standard).

\subsection{Non-Duplicating First-Stage Evaluation}

To gain intuition about the challenges of implementing this staged dynamic
semantics, consider the following example:
\begin{lstlisting}
#2 (next {fib 20}, 2+3)
\end{lstlisting}
This is a stage-\bbone\ expression of type $\rmint$; the pair inside it is a
stage-\bbone\ expression of type $(\fut\rmint)\times\rmint$. 
In this example, ${\tt fib} : \rmint \to \rmint$ is a stage-\bbtwo\ reference to the Fibonacci function.
A conventional call-by-value evaluation strategy demands that we evaluate both components of
the pair to values before we project from the pair. The problem is that
while \verb|next {fib 20}| is not a value (in the sense that additional
stage-\bbtwo\ computation steps are necessary to produce the result \verb|6765|), 
evaluating the contents of \verb|next| cannot occur as part of stage-\bbone\ evaluation.
Intuitively, the solution is to designate \verb|next {fib 20}| as a value \emph{in
stage \bbone}, even though it requires additional evaluation in stage \bbtwo.
Therefore, we evaluate the pair to
\begin{lstlisting}
#2 (next {fib 20}, 5)
\end{lstlisting}
then obtain \verb|5| as the result of projection.

Now consider a more complex example where 
stage-\bbone\ evaluation must substitute such a incompletely-evaluated
expression. The following stage-\bbtwo\ term has type $\rmint$:
\begin{lstlisting} 
prev{
  let x = (next {fib 20}, 3+4) in
  next{ prev{#1 x} * prev{#1 x} * hold{#2 x} }
}
\end{lstlisting}
Again, stage-\bbone\ evaluation will not fully reduce this term, because the answer
depends on the value of \verb|fib 20|, which is not reduced to \verb|3| until
stage \bbtwo.

If we simply treat \verb|(next {fib 20}, 7)| as a value during stage~\bbone, and
substitute it for the three occurrences of \verb|x| in the body of the
\verb|let| expression, the result of stage \bbone\ computation is
\begin{lstlisting} 
prev{
  next{ 
    prev{next {fib 20}} * prev{next {fib 20}} * 7 
  }
}
\end{lstlisting}
Finally, the $\prev$s eliminate the $\next$s to yield the final residual:
\begin{lstlisting} 
(fib 20) * (fib 20) * 7
\end{lstlisting}
Note how stage-\bbtwo\ evaluation of this expression will compute \verb|fib 20| twice.  
To avoid duplicating computations, we take a different approach.  Instead of
duplicating the contents of the $\next$ expression in the tuple, we bind the contained stage-\bbtwo\ expression to
a variable (here, $\mathtt{y}$) and duplicate only a reference to that variable.
This produces:
\begin{lstlisting} 
let y = fib 20 in y * y * 7
\end{lstlisting}

Achieving this behavior mechanically requires us to resolve a contradiction:
we must substitute for \texttt{x} in stage \bbone, but we cannot evaluate inside the $\next$ block within the tuple. 
Our solution is to replace the contents of the $\next$ with a new stage-\bbtwo\ variable and create an explicit substitution (shown with a $\mapsto$) binding that stage-\bbtwo\ variable to the $\next$'s old contents.  
This substitution then floats up to the top of the containing $\prev$ block:
\begin{lstlisting} 
prev {
[yhat|->fib 20]
  let x = (next{yhat}, 7) in
  next{prev{#1 x} * prev{#1 x} *  hold{#2 x}}
}
\end{lstlisting}
As a convention, we render the new variable with a %stylish and fashionable
hat.  We're now free to perform the stage-\bbone~substitution for {\tt x} without duplicating stage-\bbtwo\ work.
\begin{lstlisting} 
prev {
[yhat|->fib 20]
  next{
    prev{#1 (next {yhat}, 7)} * 
    prev{#1 (next {yhat}, 7)} *
    hold{#2 (next {yhat}, 7)}
  }
}
\end{lstlisting}
To evaluate the outermost $\next$, we must first partially evaluate within its body by finding all of the contained stage-\bbone~terms and reducing them. 
As a rule, these will reduce to $\next$ expressions, which the $\prev$ eliminates, leaving the variable in place:
\begin{lstlisting} 
prev {
[yhat|->fib 20]
    next{ yhat * yhat * 7 }
}
\end{lstlisting}
Once again, we lift the contents of the $\next$ into a substitution:
\begin{lstlisting} 
prev {
[yhat|->fib 20]
[zhat|->yhat*yhat*7]
    next{ zhat }
}
\end{lstlisting}
Finally, when evaluating the outer $\prev$, we must {\em reify} the contained substitutions into let statements, yielding
\begin{lstlisting} 
let yhat = fib 20 in
let zhat = yhat * yhat * 7 in z
\end{lstlisting}

Thus we have evaluated all of the stage \bbone\ expressions of this program without duplicating the contents of $\next$ blocks.

\subsection{Dynamics}
\label{ssec:dynamics}

\input {figures/dynamics}

The algorithm described above creates three different kinds of expressions which
cannot be evaluated further at a particular stage:
\begin{itemize}
\item 
Partial values ($\pvalsym$s) are stage \bbone\ terms that have been fully evaluated, 
but which may contain stage-\bbtwo\ variables wrapped in $\next$ blocks. 
In the example above, 
\verb|(|$\next \{\mathtt{\hat y}\}$\verb|,7)|.

\item Residuals ($\ressym$es) are \langTwo\ terms---stage \bbtwo\ terms whose
stage \bbone\ subexpressions have all been fully evaluated. In the example
above,
\verb|(1+2)| and \verb|(let z = y*y*7 in z)|.

\item Values ($\valsym$s) are \langTwo\ terms which are fully evaluated; these
are the results of a computation after both stages have been completed. In the
example above, the term evaluates to \verb|63|.
\end{itemize}

% would like some kind of intro here that anticipates all the complexity.
% The dynamics of \lang\ consists of three types of judgements: $\redonesym$ (stage-\bbone reduction), $\redtwosym$ (speculation), and $\reifysym$ (reification).

The $\redonesym$ judgment takes an open stage \bbone\ term to a {\em future
environment} $\xi$ and a partial value $v$.  The future environment is a mapping
from fresh stage \bbtwo\ variables (which may appear inside $\next$ blocks in
$v$) to residuals---in our example above, we represented this environment with
explicit substitutions. For all of the normal features of \lang\ 
(\ref{fig:diaSemanticsCore}), first stage evaluation has the same behavior and
effect on (partial) values as does standard evaluation, and the final future environment is
gotten by merging the future environments of the subterms.

When the \bbone\ judgment encounters a $\next$ block (\ref{fig:diaSemanticsNP}), it
searches into the block's stage \bbtwo\ content to find any contained stage
\bbone\ subexpressions and evaluate them in place.  This search process, called
\emph{speculation}, is implemented by the $\redtwosym$ judgment, which takes
a stage \bbtwo\ term to a residual.  Once the contents of the $\next$ block are
speculated into a residual ($q$), the output of $\redonesym$ is a fresh variable wrapped in a
$\next$ block ($\next~\hat y$), along with a future environment which maps that
variable to the residual ($\hat y \mapsto q$).

At all of the normal features (\ref{fig:diaSemanticsSpec}), speculation does
nothing but recursively speculate into every subexpression.  Once speculation
finds a $\prev$ block, it resumes stage \bbone\ evaluation of the contents, which
produces a future context and (by canonical forms) a $\next$-wrapped variable
($\next\{\hat y\}$).  The context is then reified (using the $\reifysym$
judgment) into a series of let bindings with $\mathtt{\hat y}$, stripped of
its $\next$, at the bottom.

Within speculation lies a subtle---if perhaps unintuitive---feature.  
Observe that speculation will traverse into both branches of a stage-\bbtwo\ {\tt if} or {\tt case} 
statement in its search for stage-\bbone\ code. 
Thus the evaluation of that stage one code will occur {\em regardless of the eventual value of the predicate},
and so a term like 
\begin{lstlisting} 
next{
  if true 
  then hold{1+2} 
  else prev{spin() (* loops forever *)}
}
\end{lstlisting}
will fail to evaluate at stage \bbone.
This behavior is why the judgment is named ``speculation."

The context ($\Gamma$) keeps track of stage \bbtwo\ variables in the input term. 
These both appear in the original program at stage \bbtwo\ and are inserted by the semantics.

As an optimization, we can include the special-case rule,
\begin{mathpar}
\inferdiaone [hat] {\red {\next~\hat y}{\cdot,\next~\hat y}}{\cdot}
\end{mathpar}
to avoid one-for-one variable bindings in the residual.
We used this implicitly in the example in the previous section.

If we change the $\next$ and $\prev$ rules to 
\begin{mathpar}
\infer {\diaone {\next~e}{\cdot,\next~q}} {\diatwo e q} \and
\infer {\diatwo{\prev~e}{v}} {\diaone e {\cdot,\next~v}} 
\end{mathpar}
and treat $\next~q$ as a partial value for any residual $q$,
then our semantics becomes rule-for-rule isomorphic to that from \cite{davies96}. This essentially bypasses the
environment bookkeeping in $\redonesym$, by inlining residuals instead of
hoisting them in \verb|let|-bindings.
From this it's clear that the semantics of \cite{davies96} and ours always produce the same value when they both terminate.
{\em Because \lang's semantics dictate that a reified residual will always be evaluated, regardless of whether its result is consumed, \lang\ programs terminate strictly less often than that of \cite{davies96}}.

Returning to our {\tt fexp} example, we can speculate on the stage \bbtwo\ term
$\verb|fn b => prev{fexp(next{b},10)}|$
to get the residual
\begin{lstlisting} 
fn b : int =>
  let x0 =
    (let x1 = 
      let x2 = 1 * b
      in x2 * x2
    in x1 * x1) * b
  in x0 * x0
\end{lstlisting}

Note how the recursion causes duplicate code in the residual.

\subsection {A Partial Evaluation System}
\label{sec:partialeval}

The dynamics described in the previous section provide a formal description of partial evaluation.
Recall that in partial evaluation systems, we start with a multivariate function $f$ for which some input is labeled {\em static} and 
some labeled {\em dynamic}.  Once the static input is provided, partial evaluation of $f$ produces
a residual that depends on only the dynamic input.  Equationally, a partial evaluator is any $p$ such that
\[
	\forall f,x. \exists f_x. [p(f,x) = f_x \text{ and } \forall y.\llbracket f \rrbracket(x,y)=\llbracket f_x \rrbracket(y)]
\]
where $\llbracket \cdot \rrbracket$ translates the text of a function to it's mathematical interpretation (a la \cite{jones96}).
Here, $x$ is the static input, $y$ is the dynamic input, and $f_x$ is the residual, also called ``f specialized to x."

% KAYVONF: good statement, but hold out for now
%The hope of partial evaluation is that $f_x$ is cheaper to execute than $f$, meaning that we can save work if we must %evaluate it many times.

By identifying static with stage \bbone\ and dynamic with stage \bbtwo, 
our dynamics can serve as a partial evaluator.   
Specifically, we encode $f$ as a \lang\ expression with a function type of the form $A\to\fut(B\to C)$
\cprotect\footnote{We can rewrite \texttt{fexp} in this form, or simply apply
the following higher-order function which makes the adjustment:
\begin{lstlisting} 
let adjust (f : $int * int -> $int) =
  fn (p : int) => 
    next{
      fn (b : int) => 
        prev{f (next {b}, p)}
    }
\end{lstlisting}}.
%
Here $A$ represents the static input, $B$ represents the dynamic input, and $C$ represents the output.

Once a stage \bbone\ argument $a:A$ is provided, we can evaluate the partially-applied
function:
$\cdot\vdash f~a \mathop{\redonesym} [\xi,v]$.
The result is an environment $\xi$ and a partial value $v$ of type $\fut(B\to
C)$, which by canonical forms must have the form $v = \next~\hat y$. 
Next, we reify this environment into a sequence of \verb|let|-bindings
enclosing $\hat y$, via $\reify\xi{\hat y}{f_a}$. 
Because reification preserves types, the resulting residual $f_a$ has type $B\to C$ in \langTwo, so we can apply it to some $b:B$
and compute the final result of the function, $f_a~b \mathop{\tworedsym} c$.

That this sequence of evaluations is in fact staged follows from our
characterizations of partial values, residuals, and values, that $\redonesym$
outputs a partial value, and that $\reifysym$ outputs an expression in \langTwo.

%\begin{remark}
%For any $\colone{e}{A}$ containing no $\next$ subexpressions, $\redonesym$ will
%always compute an empty environment, and a partial value identical to the result
%of call-by-value evaluation of $e$.
%%derivationally equivalent to standard call-by-value evaluation.
%\end{remark}

%\subsection{Metatheory}
%
%Recall that residuals live in \langTwo; we will indicate typing judgments in
%\langTwo\ with $\vdash_\bbtwo$.
%
%%\begin{definition}
%%Context $\Gamma$ is well-formed ($\Gamma\wf$) if it
%%contains only stage-2 variables.
%%\end{definition}
%
%\begin{definition}
%An environment $\xi$ is well-formed ($\Gamma\vdash\xi\wf$) if either:
%\begin{enumerate}
%\item $\xi = \cdot$; or
%\item $\xi = \xi',x:B\mapsto e$ where
%$\Gamma\vdash\xi'\wf$ and
%$\typeslangTwo[\Gamma,\dom{\xi'}] e B$
%%$\Gamma,\dom{\xi'}\vdash \coltwo{e}{B}$ and
%%$\Gamma,\dom{\xi'}\vdash e \res$.
%\end{enumerate}
%\end{definition}
%
%\begin{theorem}
%If $\typeswor e A$ then $\Gamma\wf$ and $A\istypewor$.
%\end{theorem}
%
%\begin{theorem}
%If $\diaonesub$ and $\typesone e A$ then
%\begin{enumerate}
%\item $\Gamma\vdash\xi\wf$;
%\item $\Gamma,\dom\xi\vdash \colone{v}{A}$; and
%\item $\Gamma,\dom\xi\vdash v\pval$.
%\end{enumerate}
%\end{theorem}
%
%\begin{theorem}
%If $\diatwosub$ and $\typestwo e A$ then
%\begin{enumerate}
%\item $\typeslangTwo q A$; and
%\item $\Gamma\vdash_\bbtwo q\val$.
%\end{enumerate}
%\end{theorem}
%
%\begin{theorem}\label{thm:reify-type}
%If $\Gamma\vdash\xi\wf$ and
%$\Gamma,\dom\xi\vdash \colone{\next\ \hat y}{\fut A}$
%then 
%$\reify{\xi}{\hat y}{q}$ and
%$\typeslangTwo q A$.
%\end{theorem}

%\TODO
%Note somewhere how to run stage-one non-$\fut A$ terms. For example, a stage-one
%integer term is guaranteed not to depend on the table, although one might be
%produced. One may either discard the table, or evaluate everything in the table
%(and terminating with the partial value iff everything in the table terminates).


