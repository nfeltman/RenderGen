\section{The \lang\ Language}
\label{sec:semantics}

\input {figures/grammars}
\input {figures/statics}

In this section, we describe \lang, a simple two-stage language
for which we define and analyze stage splitting.

% \lang\ is largely based off the
% language \lamCircle\ by \cite{davies96}.  
% which was used as a model for partial evaluation.  
% Our version, despite a slightly different semantics, can be used for the same purpose.
% The details of the partial evaluation view are shown in \cref{sec:partialeval}.

\lang\ is essentially two copies of a typed lambda calculus with
products, sums, and isorecursive types.%
\footnote{It is possible for different stages to have different sets of
features, but for simplicity we do not consider this.}
Every valid expression has both a type and a stage, either \bbone~or \bbtwo,
expressing in which copy of the language the term resides. Intuitively, the
stage of a term expresses \emph{when} to evaluate it---all stage-\bbone\
subexpressions are evaluated before stage-\bbtwo\ ones.

The stage-\bbone\ type $\fut A$ contains encapsulated
stage-\bbtwo\ expressions of type $A$. Terms of type $\fut A$ are treated
opaquely by stage-\bbone\ code, as (by the requirements of staging) they cannot be evaluated until stage \bbtwo.
While $\fut$ allows us to embed stage-\bbtwo\ types within stage-\bbone\ types,
there is no way to embed a stage-\bbone\ type within a stage-\bbtwo\ type.
The $\next$ constructor embeds stage-\bbtwo\ expressions into stage \bbone,
while $\prev$ embeds stage-\bbone\ expressions into stage \bbtwo.  $\next$ and $\prev$ are the
only ways in \lang\ to alter the stage of a term; we surround their arguments
with braces in \lang\ syntax to clearly indicate stage boundaries within a
program.

The grammar and type system for \lang\ is given in
\ref{fig:grammar,fig:statics}. (Typing judgments and context variables are annotated with stages.)
Only $\fut$ and its introductory and eliminatory forms $\next$ and $\prev$ affect the stage
of a term or type.
%We formulated our typing judgments in the style of \cite{davies96}, where the
%whole judgment is annotated with a stage.  
%The grammar and type system for \lang\ is given in
%\ref{fig:grammar,fig:statics}.
% We annotate typing judgments and context variables with stages;
%This is made manifest as rules which are entirely abstract over stage.
%In addition to determining the stage, $\next$ and $\prev$ are the introduction and elimination forms for $\fut$ types.
Specifically, given an argument with type $A$ at stage \bbtwo, $\next$ forms a $\fut A$ at stage \bbone.  
%That is, it forms the promise of a future $A$ out of a construction for an $A$ at the next timestep.
Stage \bbtwo\ expressions can obtain the original stage \bbtwo\ argument via the $\prev$ construct.  
Since $\prev$ operates at stage \bbtwo, this ensures no violation of causality\,\cite{cave14}.
The $\pause$ construct serves to wrap stage \bbone\ integers for use in stage \bbtwo.  
It is possible to implement $\pause$ from other \lang\ features, but
we provide it as a core primitive to simplify our examples. 

\subsection{Staged Evaluation}
\label{sec:stagedsemantics}

As a simple example of expressing staged programs in \lang, consider the following fast exponentiation algorithm, which 
calculates $b^p$ in $\log p$ time:
\[
	\mathit{fexp}(b,p) = \left \{ \begin{array}{ll} 
		1 &  p = 0 \\ 
		\mathit{fexp}(b,p/2)^2 & p \text{ even} \\ 
		b \cdot \mathit{fexp}(b,p-1) & p \text{ odd} \end{array}
	\right .
\]

% Ignoring for the moment how to define recursive functions in \lang,
\noindent
The stage-\bbone\ term below defines the function {\tt fexp} that implements the fast exponentiation algorithm:

\begin{lstlisting} 
let fexp (b : $int, e : int) : $int =
	if e == 0 then
		next{1}
	else if (e mod 2) == 0 then
		next{let x = prev{fexp(b,p/2)} in x*x}
	else
		next{prev{b} * prev{fexp(b,p-1)}}		
\end{lstlisting}

Although the code for {\tt fexp} appears very similar to the unstaged mathematical
definition above, it is in fact a staged program. The function receives a stage-\bbone\ exponent {\tt e} and a stage-\bbtwo\ base {\tt b} and returns a stage-\bbtwo\ result. The {\tt if} predicates and exponent
decomposition are all stage-\bbone\ terms, since they occur within $\prev$ blocks.
%\needsfix{Essentially, the type system is sufficient to prove the observation that all of
%the decomposition of the exponent can be done at the stage \bbone\ without
%requiring disruption of the elegant functional structure of the code.}
%
% NOTE(kayvonf): removing the following comments about binding time analysis from the text for now to improve clarity.  They will certainly be addressed in some prior section in the paper.
%
%We note that our work does not consider the problem of {\em binding time analysis}---transforming an unstaged program into a staged \lang\ program by inserting appropriate $\next$, $\prev$, and $\pause$ constructs. We assume that binding time analysis is performed manually by a programmer (as done above) or via automatic analysis of unstaged code to arrive at a valid \lang\ program used as input for subsequent splitting.
%
A key attribute of this example is that stage-\bbone\ and stage-\bbtwo\ expressions are nested. Ordinary term evaluation eliminates outermost redexes first, 
however in the case that stage \bbone\ expressions are contained inside
stage \bbtwo\ ones (such as the recurive call to {\tt fexp} above), this strategy conflicts with the precept of staged execution: that all stage-\bbone\ code be evaluated before the evaluation of stage-\bbtwo\ code. 

Thus, our dynamic semantics for \lang\ evaluates all of a term's stage \bbone\
subexpressions before any of its stage \bbtwo\ subexpressions. This results in a
stage \bbtwo\ term with no stage \bbone\ content; we say this is a term in a
monostaged
\footnote{In general, \lang could have more than two stages, in which case the
expression would be in a language with one fewer stage.}
language called \langTwo. Then, we perform the remainder of the evaluation with 
$\tworedsym$, an ordinary dynamic semantics for \langTwo\ (the rules for this
judgment are not shown, but they are standard).

\subsection{Non-Duplicating First-Stage Evaluation}

To gain intuition about the challenges of implementing this staged dynamic
semantics, consider the following example:
\begin{lstlisting}
#2 (next {1+2}, 3+4)
\end{lstlisting}
This is a stage-\bbone\ expression of type $\rmint$; the pair inside it is a
stage-\bbone\ expression of type $(\fut\rmint)\times\rmint$. A conventional
call-by-value evaluation strategy demands that we evaluate both components of
the pair to values before we project from the pair. The problem is that
while \verb|next {1+2}| is not a value (in the sense that additional
stage-\bbtwo\ computation steps are necessary to produce the result \verb|3|), evaluating the contents of \verb|next| cannot occur as part of stage-\bbone\ evaluation.
Intuitively, the solution is to designate \verb|next {1+2}| as a value \emph{in
stage \bbone}, even though it requires additional evaluation in stage \bbtwo.
Therefore, we evaluate the pair to
\begin{lstlisting}
#2 (next {1+2}, 7)
\end{lstlisting}
then obtain \verb|7| as the result of projection.

Now consider a more complex example where 
stage-\bbone\ evaluation must substitute such a incompletely-evaluated
expression. The following stage-\bbtwo\ term has type $\rmint$:
\begin{lstlisting} 
prev{
  let x = (next {1+2}, 3+4) in
  next{ prev{#1 x} * prev{#1 x} * hold{#2 x} }
}
\end{lstlisting}
Again, stage-\bbone\ evaluation will not fully reduce this term, because the answer
depends on the value of \verb|1+2|, which is not reduced to \verb|3| until
stage \bbtwo.

If we simply treat \verb|(next {1+2}, 7)| as a value during stage~\bbone, and
substitute it for the three occurrences of \verb|x| in the body of the
\verb|let| expression, the result of stage \bbone\ computation is
\begin{lstlisting} 
prev{
  next{ prev{next {1+2}} * prev{next {1+2}} * 7 }
}
\end{lstlisting}
Finally, the $\prev$s eliminate the $\next$s to yield the final residual:
\begin{lstlisting} 
(1+2) * (1+2) * 7
\end{lstlisting}
Stage-\bbtwo\ evaluation of this expression will compute \verb|1+2| twice. Of
course, this is not particularly expensive, but in general, the duplicated
computation could be anything, even a recursive call to the function! To avoid duplicating
computations, we take a different approach.  Instead of
duplicating the contents of the $\next$ expression in the tuple, we bind the contained stage-\bbtwo\ expression to
a variable (here, $\mathtt{y}$) and duplicate only a reference to that variable.
This produces:
\begin{lstlisting} 
let y = 1+2 in y * y * 7
\end{lstlisting}

Achieving this behavior mechanically requires us to resolve a contradiction:
we must substitute for \texttt{x} in stage \bbone, but we cannot evaluate inside the $\next$ block within the tuple. 
Our solution is to replace the contents of the $\next$ with a new stage-\bbtwo\ variable and create an explicit substitution (shown with a $\mapsto$) binding that stage-\bbtwo\ variable to the $\next$'s old contents.  
This substitution then floats up to the top of the containing $\prev$ block:
\begin{lstlisting} 
prev {
[yhat|->1+2]
  let x = (next{yhat}, 7) in
  next{prev{#1 x} * prev{#1 x} *  hold{#2 x}}
}
\end{lstlisting}
As a convention, we render the new variable with a %stylish and fashionable
hat.  We're now free to perform the stage-\bbone~substitution for {\tt x} without duplicating stage-\bbtwo\ work.
\begin{lstlisting} 
prev {
[y|->1+2]
  next{
    prev{#1 (next {yhat}, 7)} * 
    prev{#1 (next {yhat}, 7)} *
    hold{#2 (next {yhat}, 7)}
  }
}
\end{lstlisting}
To evaluate the outermost $\next$, we must first partially evaluate within its body by finding all of the contained stage-\bbone~terms and reducing them. 
As a rule, these will reduce to $\next$ expressions, which the $\prev$ eliminates, leaving the variable in place:
\begin{lstlisting} 
prev {
[yhat|->1+2]
    next{ yhat * yhat * 7 }
}
\end{lstlisting}
Once again, we lift the contents of the $\next$ into a substitution:
\begin{lstlisting} 
prev {
[yhat|->1+2]
[zhat|->yhat*yhat*7]
    next{ zhat }
}
\end{lstlisting}
Finally, when evaluating the outer $\prev$, we must {\em reify} the contained substitutions into let statements, yielding
\begin{lstlisting} 
let yhat = 1+2 in
let zhat = yhat * yhat * 7 in z
\end{lstlisting}

Thus we have evaluated all of the stage \bbone\ expressions of this program without duplicating the contents of $\next$ blocks.

\subsection{Dynamics}
\label{ssec:dynamics}

\input {figures/dynamics}

%{{{ stuff nico commented out
%Previous work (\cite{davies96}) focuses on the correspondence between the type system and existing temporal logics, whereas we care more about operational behavior and cost.  In this section, we'll consider a few proposals for our language before settling on one we like.  All of the proposals are call-by-value, differing primarily in how they handle values of $\fut$ type.

%\subsection{The Erasure Semantics}
%
%We first consider the {\em erasure semantics}, so called because it corresponds to what one would get by interpreting \lamStaged as a single-stage language, ignoring all of the $\next$ and $\prev$ terms.  This gives us two judgments, $\erasone$ and $\erastwo$, corresponding to {\em multistage evaluation} at \bbone and at \bbtwo.  We call these judgments  ``multistage'' because they cause work to happen at both stages.
%
%Both judgments behave normally at non-staged features.  We cover their behavior at staged features below:
%
%\begin{mathpar}
%\infer {\next~e \erasone \next~v} {e \erastwo v} \and
%\infer {\prev~e \erastwo \next~v} {e \erasone v} \and
%\infer {\pause~e \erasone \next~i} {e \erasone i}
%\end{mathpar}
%
%Essentially, we immediately evaluate under the $\next$, yielding a value for $\fut$ types. The $\prev$ terms remove this wrapper.  As expected, $\pause$ also gives us a way to inject into the wrapper at integers.
%
%The erasure semantics has some undesirable properties.  By intention, it interleaves the execution of stage-\bbone~and stage-\bbtwo~code, so the evaluation can't really be said to be staged (i.e. stage-\bbone~work is done before stage-\bbtwo~work).  Moreover, the erasure semantics cannot be equivalent to any semantics which does have this property!  To see why, consider the following code, which types to int at \bbtwo:
%
%\begin{lstlisting} 
%if 5*4*3*2 > 111 then
%	hold{2+4}
%else
%	prev{ loopForever () (* does not terminate *) }
%\end{lstlisting}
%
%Under the erasure semantics (using $\erastwo$), this code takes the top branch and evaluates to 6.  But in order know that the {\tt loopForever} function need not be called, the predicate had to be evaluated prior.  But the predicate is stage-\bbtwo, whereas {\tt loopForever} is stage-\bbone.  To borrow terminology from \cite{cave14}, this violates causality.  In order to avoid this problem, a valid semantics must {\em speculate} down the branches of any stage-\bbtwo~if or case statement (or similarly into the body of a stage-\bbtwo function) to find and evaluate all of the stage-\bbone~code.  Both of the other semantics we will consider have this property.
%
%The benefit of the erasure semantics is that it's very natural, and has a familiar cost model.  It also {\em obviously} produces the ``correct'' answer, so we can use the erasure semantics as a reference to prove the reasonableness of any other semantics.
%
%\subsection{Meta Semantics}
%
%A different semantics was provided in \cite{davies96}.  We briefly review a two-stage version of that semantics here.
%
%In the erasure semantics, $\next v$ is a value only if $v$ is fully reduced.  But in the meta semantics, $\next e$ is a value only if $e$ has no $\prev$ terms; $v$ is allowed to have unreduced stage-2 computation. 
%
%...
%
%The Davies semantics is comprised of two mutually recursive judgments: $\daviesz$ and $\davieso$.  For some $\colone e A$, the $\daviesz$ judgment evaluates only the first-stage parts of $e$, leaving unevaluated second-stage code within $\next$s.  (... This essentially gives us partial evaluation, and we're left to just evaluate the residual normally to get multi-stage evaluation...) 
%
%The benefit of the meta semantics is that it gives us a very explicit notion of partial evaluation.  This also, by construction, means that the meta semantics does all of the first stage-work {\em before} the second stage work begins. 
%
%The $\next$-by-name behavior of the meta semantics of course means that it happily duplicates second-stage code, which could increase the cost.  This makes reasoning about second-stage cost rather difficult.
%
%\begin{lstlisting} 
%let x = next {4+5} in
%next{prev{x} * prev{x}}
%\end{lstlisting}
%
%\subsection{Our Semantics}
%
%We desire a semantics that meets the following goals:
%
%\begin{enumerate}
%\item Modulo termination, it should be equivalent to the erasure semantics.
%\item All of the first stage work should be completed before second stage work.  Ideally, it should just have a notion of partial evaluation, like the meta semantics.
%\item Should be $\next$-by-value, rather than $\next$-by-name, like the erasure semantics.  
%\end{enumerate}
%
%We meet all of these goals.
%}}}
%{{{ stuff carlo commented out
%Abstractly, we can think of our evaluation as proceeding in the standard way for
%stage-1 code. When the evaluator encounters a $\next \{e\}$ expression, it
%places $e$ off to the side in a context and replaces the whole expression with a
%reference to the context entry.  These references are then passed around as
%stage-1 values for $\fut$ types.  But what if $e$ contains $\prev$ expressions?
%To ensure that all stage-1 code is evaluated before any stage-2 code, we must
%evaluate all of the 1-code contained in $e$ before inserting it into the table.
%This entails searching $e$ for all contained $\prev$s and evaluating them in
%place.  

%The evaluation judgment operates on stage-1 code, whereas the
%speculation operates on stage-2 code.  Since $\next$ and $\prev$ are the
%crossover points between 1-code and 2-code, they are correspondingly the only
%places where the evaluation and speculation judgments depend on the other. 
%}}}

The algorithm described above creates three different kinds of expressions which
cannot be evaluated further at a particular stage:
\begin{itemize}
\item 
Partial values ($\pvalsym$s) are stage \bbone\ terms that have been fully evaluated, 
but which may contain stage-\bbtwo\ variables wrapped in $\next$ blocks. 
In the example above, 
\verb|(|$\next \{\mathtt{\hat y}\}$\verb|,7)|.

\item Residuals ($\ressym$es) are \langTwo\ terms---stage \bbtwo\ terms whose
stage \bbone\ subexpressions have all been fully evaluated. In the example
above,
\verb|(1+2)| and \verb|(let z = y*y*7 in z)|.

\item Values ($\valsym$s) are \langTwo\ terms which are fully evaluated; these
are the results of a computation after both stages have been completed. In the
example above, the term evaluates to \verb|63|.
\end{itemize}

% would like some kind of intro here that anticipates all the complexity.
% The dynamics of \lang\ consists of three types of judgements: $\redonesym$ (stage-\bbone reduction), $\redtwosym$ (speculation), and $\reifysym$ (reification).

The $\redonesym$ judgment takes an open stage \bbone\ term to a {\em future
environment} $\xi$ and a partial value $v$.  The future environment is a mapping
from fresh stage \bbtwo\ variables (which may appear inside $\next$ blocks in
$v$) to residuals---in our example above, we represented this environment with
explicit substitutions. For all of the normal features of \lang\ 
(\ref{fig:diaSemanticsCore}), first stage evaluation has the same behavior and
effect on (partial) values as does standard evaluation, and the final future environment is
gotten by merging the future environments of the subterms.

When the \bbone\ judgment encounters a $\next$ block (\ref{fig:diaSemanticsNP}), it
searches into the block's stage \bbtwo\ content to find any contained stage
\bbone\ subexpressions and evaluate them in place.  This search process, called
\emph{speculation}, is implemented by the $\redtwosym$ judgment, which takes
a stage \bbtwo\ term to a residual.  Once the contents of the $\next$ block are
speculated into a residual ($q$), the output of $\redonesym$ is a fresh variable wrapped in a
$\next$ block ($\next~\hat y$), along with a future environment which maps that
variable to the residual ($\hat y \mapsto q$).

At all of the normal features (\ref{fig:diaSemanticsSpec}), speculation does
nothing but recursively speculate into every subexpression.  Once speculation
finds a $\prev$ block, it resumes stage \bbone\ evaluation of the contents, which
produces a future context and (by canonical forms) a $\next$-wrapped variable
($\next\{\hat y\}$).  The context is then reified (using the $\reifysym$
judgment) into a series of let bindings with $\mathtt{\hat y}$, stripped of
its $\next$, at the bottom.

Within speculation lies a subtle---if perhaps unintuitive---feature.  
Observe that speculation will traverse into both branches of a stage-\bbtwo\ {\tt if} or {\tt case} 
statement in its search for stage-\bbone\ code. 
Thus the evaluation of that stage one code will occur {\em regardless of the eventual value of the predicate},
and so a term like 
\begin{lstlisting} 
next{
  if true 
  then hold{1+2} 
  else prev{spin() (* loops forever *)}
}
\end{lstlisting}
will fail to evaluate at stage \bbone.
This behavior is why the judgment is named ``speculation."

The context ($\Gamma$) keeps track of stage \bbtwo\ variables in the input term. 
These both appear in the original program at stage \bbtwo\ and are inserted by the semantics.

As an optimization, we can include the special-case rule,
\begin{mathpar}
\inferdiaone [hat] {\red {\next~\hat y}{\cdot,\next~\hat y}}{\cdot}
\end{mathpar}
to avoid one-for-one variable bindings in the residual.
We used this implicitly in the example in the previous section.

If we change the $\next$ and $\prev$ rules to 
\begin{mathpar}
\infer {\diaone {\next~e}{\cdot,\next~q}} {\diatwo e q} \and
\infer {\diatwo{\prev~e}{v}} {\diaone e {\cdot,\next~v}} 
\end{mathpar}
and treat $\next~q$ as a partial value for any residual $q$,
then our semantics becomes rule-for-rule isomorphic to that from \cite{davies96}. This essentially bypasses the
environment bookkeeping in $\redonesym$, by inlining residuals instead of
hoisting them in \verb|let|-bindings.
From this it's clear that the semantics of \cite{davies96} and ours always produce the same value when they both terminate.
{\em Because \lang's semantics dictate that a reified residual will always be evaluated, regardless of whether its result is consumed, \lang\ programs terminate strictly less often than that of \cite{davies96}}.

\subsection {A Partial Evaluation System}
\label{sec:partialeval}

The dynamics described in the previous section provide a formal description of partial evaluation.
Recall that in partial evaluation systems, we start with a multivariate function $f$ for which some input is labeled {\em static} and 
some labeled {\em dynamic}.  Once the static input is provided, partial evaluation of $f$ produces
a residual that depends on only the dynamic input.  Equationally, a partial evaluator is any $p$ such that
\[
	\forall f,x. \exists f_x. [p(f,x) = f_x \text{ and } \forall y.\llbracket f \rrbracket(x,y)=\llbracket f_x \rrbracket(y)]
\]
where $\llbracket \cdot \rrbracket$ translates the text of a function to it's mathematical interpretation (a la \cite{jones96}).
Here, $x$ is the static input, $y$ is the dynamic input, and $f_x$ is the residual, also called ``f specialized to x."

% KAYVONF: good statement, but hold out for now
%The hope of partial evaluation is that $f_x$ is cheaper to execute than $f$, meaning that we can save work if we must %evaluate it many times.

By identifying static with stage \bbone\ and dynamic with stage \bbtwo, 
our dynamics can serve as a partial evaluator.   
Specifically, we encode $f$ as a \lang\ expression with a function type of the form $A\to\fut(B\to C)$
\cprotect\footnote{We can rewrite \texttt{fexp} in this form, or simply apply
the following higher-order function which makes the adjustment:
\begin{lstlisting} 
let adjust (f : $int * int -> $int) =
  fn (p : int) => 
    next{
      fn (b : int) => 
        prev{f (next {b}, p)}
    }
\end{lstlisting}}.
%
Here $A$ represents the static input, $B$ represents the dynamic input, and $C$ represents the output.

Once a stage \bbone\ argument $a:A$ is provided, we can evaluate the partially-applied
function:
$\cdot\vdash f~a \mathop{\redonesym} [\xi,v]$.
The result is an environment $\xi$ and a partial value $v$ of type $\fut(B\to
C)$, which by canonical forms must have the form $v = \next~\hat y$. 
Next, we reify this environment into a sequence of \verb|let|-bindings
enclosing $\hat y$, via $\reify\xi{\hat y}{f_a}$. 
Because reification preserves types, the resulting residual $f_a$ has type $B\to C$ in \langTwo, so we can apply it to some $b:B$
and compute the final result of the function, $f_a~b \mathop{\tworedsym} c$.

That this sequence of evaluations is in fact staged follows from our
characterizations of partial values, residuals, and values, that $\redonesym$
outputs a partial value, and that $\reifysym$ outputs an expression in \langTwo.

\begin{remark}
For any $\colone{e}{A}$ containing no $\next$ subexpressions, $\redonesym$ will
always compute an empty environment, and a partial value identical to the result
of call-by-value evaluation of $e$.
%derivationally equivalent to standard call-by-value evaluation.
\end{remark}

%\subsection{Metatheory}
%
%Recall that residuals live in \langTwo; we will indicate typing judgments in
%\langTwo\ with $\vdash_\bbtwo$.
%
%%\begin{definition}
%%Context $\Gamma$ is well-formed ($\Gamma\wf$) if it
%%contains only stage-2 variables.
%%\end{definition}
%
%\begin{definition}
%An environment $\xi$ is well-formed ($\Gamma\vdash\xi\wf$) if either:
%\begin{enumerate}
%\item $\xi = \cdot$; or
%\item $\xi = \xi',x:B\mapsto e$ where
%$\Gamma\vdash\xi'\wf$ and
%$\typeslangTwo[\Gamma,\dom{\xi'}] e B$
%%$\Gamma,\dom{\xi'}\vdash \coltwo{e}{B}$ and
%%$\Gamma,\dom{\xi'}\vdash e \res$.
%\end{enumerate}
%\end{definition}
%
%\begin{theorem}
%If $\typeswor e A$ then $\Gamma\wf$ and $A\istypewor$.
%\end{theorem}
%
%\begin{theorem}
%If $\diaonesub$ and $\typesone e A$ then
%\begin{enumerate}
%\item $\Gamma\vdash\xi\wf$;
%\item $\Gamma,\dom\xi\vdash \colone{v}{A}$; and
%\item $\Gamma,\dom\xi\vdash v\pval$.
%\end{enumerate}
%\end{theorem}
%
%\begin{theorem}
%If $\diatwosub$ and $\typestwo e A$ then
%\begin{enumerate}
%\item $\typeslangTwo q A$; and
%\item $\Gamma\vdash_\bbtwo q\val$.
%\end{enumerate}
%\end{theorem}
%
%\begin{theorem}\label{thm:reify-type}
%If $\Gamma\vdash\xi\wf$ and
%$\Gamma,\dom\xi\vdash \colone{\next\ \hat y}{\fut A}$
%then 
%$\reify{\xi}{\hat y}{q}$ and
%$\typeslangTwo q A$.
%\end{theorem}

\TODO
Note somewhere how to run stage-one non-$\fut A$ terms. For example, a stage-one
integer term is guaranteed not to depend on the table, although one might be
produced. One may either discard the table, or evaluate everything in the table
(and terminating with the partial value iff everything in the table terminates).


