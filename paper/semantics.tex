\section {Staged Programming in \lang}
\label{sec:staging}
\begin{figure*}
\label{fig:quickselect}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting} 
datatype list = Empty | Cons of int * list
fun partition (p : int, l : list) 
  : (int*list*list) =
  case unroll l of 
    Empty => (0,Empty, Empty) 
  | Cons (h,t) =>
      let (s,left,right) = partition (p,t) in
      if h<p 
      then (s+1,Cons(h,left),right)
      else (s,left,Cons(h,right))

fun qs (l : list, k : int) : int = 
  case l of
    Empty => 0
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
        case compare k n of
          LT => qs (left, k)
        | EQ => h
        | GT => qs (right, k-n-1)
\end{lstlisting}
\caption{Unstaged Code}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting} 
datatype list = Empty | Cons of int * list
fun partition (p : int, l : list) = ...

fun qs (l : list, k : $int) : $int = 
  case l of
    1`Empty` => next {2`0`}
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
      next{
        let n = hold{n} in
          case compare prev{k} n of
            LT => prev {qs (left k)}
          | EQ => hold {h}
          | GT => prev {qs (right, next{prev{k}-n-1)}}
      }	
\end{lstlisting}
\caption{Staged Code}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting} 
datatype list = Empty | Cons of int * list
fun partition (p : int, l : list) = ...
	
datatype tree = Branch of int * int * tree * tree
                | Leaf

fun qs1 (l : list) : tree =
  case l of
    Empty => Leaf
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
      Branch (n, h, qs1 left, qs1 right)

fun qs2 (p : tree, k : int) : int = 
  case unroll p of
    Leaf => 0
  | Branch (n,h,p1,p2) => 
      case compare k n of
        LT => qs2 (p1,k)
      | EQ => h
      | GT => qs2 (p2,k-n-1)
\end{lstlisting}
\caption{Split Code}
\end{minipage}
\caption{Caption place holder}
\end{figure*}

For an example of an algorithm amenable to staging techniques,
consider the quickselect algorithm in [figure part (a)],
which finds the $k$th largest element of a list.
It operates by inspecting the head of the list, 
partitioning the rest of the list by the head,
comparing the size of the partition to the desired index,
and the recursively selecting on the correct sublist.
Assuming that the list is randomly sorted, 
quickselect will take expected $O(n)$ time, where $n$ is the size of the list.

Importantly, quickselect has property that the partitioning of the list does not depend on $k$, 
even through the recursive boundary.\footnote{There is a control-dependence on $k$, but we can ignore that for now.}
We can leverage this dependency pattern to split quickselect into two other functions:
one which precomputes all of the partitions of the input list to build a binary search tree,
and another which uses this tree to perform an accelerated index lookup.
This split version of quickselect is shown in [figure part (c)].
One advantage of this form is that the tree can be built once per list
and then used to accelerate many lookups.

The goal of our work is to automate this splitting transformation.
Our first step is to define a language which clearly and unambiguously specifies how its terms should be split.
Ideally, only minimal refactoring should be required to write terms within this language,
and from there, the type system should be enough to prove that a valid splitting exists.

To this end, we present \lang.
The main idea of \lang\ is that all parts of terms defined in it can be identified with one of two {\em stages}, namely \bbone\ or \bbtwo.
Intuitively, the stage of a term expresses \emph{when} to evaluate it---all stage-\bbone\
subexpressions are evaluated before stage-\bbtwo\ ones.
Correspondingly, after splitting those parts of the \lang\ term in \bbone\ will end up in the precomputation, 
and those parts in \bbtwo\ will end up in the residual.
Within well-typed terms, information can flow from stage \bbone\ to stage \bbtwo\ portions,
but never from \bbtwo\ to \bbone.  
Indeed this is a necessary property if we want to be able to split the term.

[Figure part (b)] shows a staged implementation of quickselect in \lang.
As before, the inputs to the function are the list to select from and the index to select,
but now the latter is represented with the type $\fut\rmint$ rather than $\rmint$.
The difference here is that an $\rmint$ is an integer available at the current stage (stage \bbone), 
whereas a $\fut\rmint$ is an integer available only at the next stage (stage \bbtwo).
Naturally the output type, representing the $k$th largest element of the list,
is also $\fut\rmint$, since it cannot be known until the next stage.

Each construct in the body of quickselect is now associated with a stage via an interleaving of $\next$ and $\prev$ blocks.  
Specifically, $\next$ occurs in a stage \bbone\ context and indicates that the contents of its block are stage \bbtwo, 
whereas $\prev$ occurs in a stage \bbtwo\ context and indicates that the contents of its block is stage \bbone.
(We adapt the convention convention that the top-level context is stage \bbone.)
The output type of a $\next$ block is the $\fut$'d version of the type of its stage \bbtwo\ contents.  
For example, \verb|next{0}| from above has the type $\fut\rmint$.
Correspondingly, $\prev$ requires that its stage \bbone\ contents have a $\fut$ type, and it eliminates the wrapper.
For example, \verb|prev{k}| from above has type $\rmint$ at stage \bbtwo, since $k$ is bound to a $\fut\rmint$ at stage \bbone.
These type restrictions essentially enforce that ``later stage content" is always treated hygienically at stage \bbone,
which is necessary to admit a properly staged implementation.

The code also contains two $\pause$ blocks.  
This construct has same stage signature as $\prev$,
but instead of ``unwrapping" $\fut$ types it simply promotes integers from stage \bbone\ to stage \bbtwo.
\footnote{It will turn out that $\pause$ is implementable---though it takes some effort---from our other language features.
We instead provide it as a primitive to shorten examples.  
Furthermore, it would be wise to extend $\pause$ to other base types, if we had them, and to products and sums thereof.
This is related to the notion of {\em mobility} in \cite{murphy05} and {\em stability} in \cite{krishnaswami13}.}

But for the $\fut$, $\next$, $\prev$, and $\pause$ constructs, 
the staged version of quickselect is virtually identical to the unstaged version.
The constructs that were added were placed in order to maximize the work done at stage \bbone\ while still conforming to the type signature.
It would have also been valid to simply move the whole input list unchanged into stage \bbtwo\ at the very beginning, 
but that would not be particularly interesting since it would result in an effectively trivial split 
that's just the identity at stage \bbone\ and plus quickselect at stage \bbtwo.
There has been the extensive research into the question of how to automatically add staging annotations to unstaged code.
This process is known as {\em binding time analysis}, and we do not consider it here.
Instead, we assume that all input programs are properly staged according to some programmer's intent.

\section{\lang\ Statics and Dynamics}
\label{sec:semantics}

\input {figures/grammars}
\input {figures/statics}

As stated in \cref{sec:staging}, we operate on a language called \lang,
which is a typed two-stage lambda calculus featuring products, sums, and isorecursive types.

\subsection{Statics}
The grammar and type system of \lang\ are given in \ref{fig:grammar,fig:statics}. 
They are a simple adaptation of those of \cite{davies96}, 
restricted to two stages\footnote{This restriction is not a big deal...} and extended with general sums and recursion.

Typing judgments and context variables are annotated with stages after an $@$ symbol.
Only $\fut$ and its introductory and eliminatory forms $\next$ and $\prev$ affect the stage
of a term or type.

\footnote{It is possible for different stages to have different sets of
features, but for simplicity we do not consider this.}
Every valid expression has both a type and a stage, either \bbone~or \bbtwo. 

The stage-\bbone\ type $\fut A$ contains encapsulated
stage-\bbtwo\ expressions of type $A$. Terms of type $\fut A$ are treated
opaquely by stage-\bbone\ code, as (by the requirements of staging) they cannot be evaluated until stage \bbtwo.
While $\fut$ allows us to embed stage-\bbtwo\ types within stage-\bbone\ types,
there is no way to embed a stage-\bbone\ type within a stage-\bbtwo\ type.
That is, there is a one-way dependence between stages at the term level.

Alternatively, the stages are mutually dependent at the term level.
The $\next$ constructor embeds stage-\bbtwo\ expressions into stage \bbone,
while $\prev$ embeds stage-\bbone\ expressions into stage \bbtwo.  $\next$ and $\prev$ are the
only ways in \lang\ to alter the stage of a term; we surround their arguments
with braces in \lang\ syntax to clearly indicate stage boundaries within a
program.

%We formulated our typing judgments in the style of \cite{davies96}, where the
%whole judgment is annotated with a stage.  
%The grammar and type system for \lang\ is given in
%\ref{fig:grammar,fig:statics}.
% We annotate typing judgments and context variables with stages;
%This is made manifest as rules which are entirely abstract over stage.
%In addition to determining the stage, $\next$ and $\prev$ are the introduction and elimination forms for $\fut$ types.
Specifically, given an argument with type $A$ at stage \bbtwo, $\next$ forms a $\fut A$ at stage \bbone.  
%That is, it forms the promise of a future $A$ out of a construction for an $A$ at the next timestep.
Stage \bbtwo\ expressions can obtain the original stage \bbtwo\ argument via the $\prev$ construct.  
Since $\prev$ operates at stage \bbtwo, this ensures no violation of causality,\cite{cave14}.
The $\pause$ construct serves to wrap stage \bbone\ integers for use in stage \bbtwo.  
It is possible to implement $\pause$ from other \lang\ features, but
we provide it as a core primitive to simplify our examples. 

Recall the fast exponent function from above.
We present a valid staging of it here:
\begin{lstlisting} 
let fexp (b : $int, p : int) : $int =
	if p == 0 then
		next{1}
	else if (p mod 2) == 0 then
		next{let x = prev{fexp(b,p/2)} in x*x}
	else
		next{prev{b} * prev{fexp(b,p-1)}}		
\end{lstlisting}

\TODO explain why we staged this the way we did

The function receives a stage-\bbone\ exponent {\tt e} and a stage-\bbtwo\ base {\tt b} and returns a stage-\bbtwo\ result. 
The {\tt if} predicates and exponent decomposition are all stage-\bbone\ terms, since they occur within $\prev$ blocks.

\subsection{Dynamics}
\label{sec:stagedsemantics}

A key attribute of the quickselect example is that stage-\bbone\ and stage-\bbtwo\ expressions are nested. 
Ordinary term evaluation eliminates outermost redexes first, 
however in the case that stage \bbone\ expressions are contained inside stage \bbtwo\ ones 
(such as the recurive call to {\tt fexp} above), 
this strategy conflicts with the precept of staged execution: 
that all stage-\bbone\ code be evaluated before the evaluation of stage-\bbtwo\ code. 

Thus, our dynamic semantics for \lang\ evaluates all of a term's stage \bbone\
subexpressions before any of its stage \bbtwo\ subexpressions. This results in a
stage \bbtwo\ term with no stage \bbone\ content; we say this is a term in a
monostaged language called \langTwo. Then, we perform the remainder of the evaluation with 
$\tworedsym$, an ordinary dynamic semantics for \langTwo\ (the rules for this
judgment are not shown, but they are standard).

\subsection{Non-Duplicating First-Stage Evaluation}

To gain intuition about the challenges of implementing this staged dynamic
semantics, consider the following example:
\begin{lstlisting}
#2 (next {fib 20}, 2+3)
\end{lstlisting}
This is a stage-\bbone\ expression of type $\rmint$; the pair inside it is a
stage-\bbone\ expression of type $(\fut\rmint)\times\rmint$. 
In this example, ${\tt fib} : \rmint \to \rmint$ is a stage-\bbtwo\ reference to the Fibonacci function.
A conventional call-by-value evaluation strategy demands that we evaluate both components of
the pair to values before we project from the pair. The problem is that
while \verb|next {fib 20}| is not a value (in the sense that additional
stage-\bbtwo\ computation steps are necessary to produce the result \verb|6765|), 
evaluating the contents of \verb|next| cannot occur as part of stage-\bbone\ evaluation.
Intuitively, the solution is to designate \verb|next {fib 20}| as a value \emph{in
stage \bbone}, even though it requires additional evaluation in stage \bbtwo.
Therefore, we evaluate the pair to
\begin{lstlisting}
#2 (next {fib 20}, 5)
\end{lstlisting}
then obtain \verb|5| as the result of projection.

Now consider a more complex example where 
stage-\bbone\ evaluation must substitute such a incompletely-evaluated
expression. The following stage-\bbtwo\ term has type $\rmint$:
\begin{lstlisting} 
prev{
  let x = (next {fib 20}, 3+4) in
  next{ prev{#1 x} * prev{#1 x} * hold{#2 x} }
}
\end{lstlisting}
Again, stage-\bbone\ evaluation will not fully reduce this term, because the answer
depends on the value of \verb|fib 20|, which is not reduced to \verb|3| until
stage \bbtwo.

If we simply treat \verb|(next {fib 20}, 7)| as a value during stage~\bbone, and
substitute it for the three occurrences of \verb|x| in the body of the
\verb|let| expression, the result of stage \bbone\ computation is
\begin{lstlisting} 
prev{
  next{ 
    prev{next {fib 20}} * prev{next {fib 20}} * 7 
  }
}
\end{lstlisting}
Finally, the $\prev$s eliminate the $\next$s to yield the final residual:
\begin{lstlisting} 
(fib 20) * (fib 20) * 7
\end{lstlisting}
Note how stage-\bbtwo\ evaluation of this expression will compute \verb|fib 20| twice.  
To avoid duplicating computations, we take a different approach.  Instead of
duplicating the contents of the $\next$ expression in the tuple, we bind the contained stage-\bbtwo\ expression to
a variable (here, $\mathtt{y}$) and duplicate only a reference to that variable.
This produces:
\begin{lstlisting} 
let y = fib 20 in y * y * 7
\end{lstlisting}

Achieving this behavior mechanically requires us to resolve a contradiction:
we must substitute for \texttt{x} in stage \bbone, but we cannot evaluate inside the $\next$ block within the tuple. 
Our solution is to replace the contents of the $\next$ with a new stage-\bbtwo\ variable and create an explicit substitution (shown with a $\mapsto$) binding that stage-\bbtwo\ variable to the $\next$'s old contents.  
This substitution then floats up to the top of the containing $\prev$ block:
\begin{lstlisting} 
prev {
[yhat|->fib 20]
  let x = (next{yhat}, 7) in
  next{prev{#1 x} * prev{#1 x} *  hold{#2 x}}
}
\end{lstlisting}
As a convention, we render the new variable with a %stylish and fashionable
hat.  We're now free to perform the stage-\bbone~substitution for {\tt x} without duplicating stage-\bbtwo\ work.
\begin{lstlisting} 
prev {
[yhat|->fib 20]
  next{
    prev{#1 (next {yhat}, 7)} * 
    prev{#1 (next {yhat}, 7)} *
    hold{#2 (next {yhat}, 7)}
  }
}
\end{lstlisting}
To evaluate the outermost $\next$, we must first partially evaluate within its body by finding all of the contained stage-\bbone~terms and reducing them. 
As a rule, these will reduce to $\next$ expressions, which the $\prev$ eliminates, leaving the variable in place:
\begin{lstlisting} 
prev {
[yhat|->fib 20]
    next{ yhat * yhat * 7 }
}
\end{lstlisting}
Once again, we lift the contents of the $\next$ into a substitution:
\begin{lstlisting} 
prev {
[yhat|->fib 20]
[zhat|->yhat*yhat*7]
    next{ zhat }
}
\end{lstlisting}
Finally, when evaluating the outer $\prev$, we must {\em reify} the contained substitutions into let statements, yielding
\begin{lstlisting} 
let yhat = fib 20 in
let zhat = yhat * yhat * 7 in z
\end{lstlisting}

Thus we have evaluated all of the stage \bbone\ expressions of this program without duplicating the contents of $\next$ blocks.

\subsection{Dynamics}
\label{ssec:dynamics}

\input {figures/dynamics}

The algorithm described above creates three different kinds of expressions which
cannot be evaluated further at a particular stage:
\begin{itemize}
\item 
Partial values ($\pvalsym$s) are stage \bbone\ terms that have been fully evaluated, 
but which may contain stage-\bbtwo\ variables wrapped in $\next$ blocks. 
In the example above, 
\verb|(|$\next \{\mathtt{\hat y}\}$\verb|,7)|.

\item Residuals ($\ressym$es) are \langTwo\ terms---stage \bbtwo\ terms whose
stage \bbone\ subexpressions have all been fully evaluated. In the example
above,
\verb|(1+2)| and \verb|(let z = y*y*7 in z)|.

\item Values ($\valsym$s) are \langTwo\ terms which are fully evaluated; these
are the results of a computation after both stages have been completed. In the
example above, the term evaluates to \verb|63|.
\end{itemize}

% would like some kind of intro here that anticipates all the complexity.
% The dynamics of \lang\ consists of three types of judgements: $\redonesym$ (stage-\bbone reduction), $\redtwosym$ (speculation), and $\reifysym$ (reification).

The $\redonesym$ judgment takes an open stage \bbone\ term to a {\em future
environment} $\xi$ and a partial value $v$.  The future environment is a mapping
from fresh stage \bbtwo\ variables (which may appear inside $\next$ blocks in
$v$) to residuals---in our example above, we represented this environment with
explicit substitutions. For all of the normal features of \lang\ 
(\ref{fig:diaSemanticsCore}), first stage evaluation has the same behavior and
effect on (partial) values as does standard evaluation, and the final future environment is
gotten by merging the future environments of the subterms.

When the \bbone\ judgment encounters a $\next$ block (\ref{fig:diaSemanticsNP}), it
searches into the block's stage \bbtwo\ content to find any contained stage
\bbone\ subexpressions and evaluate them in place.  This search process, called
\emph{speculation}, is implemented by the $\redtwosym$ judgment, which takes
a stage \bbtwo\ term to a residual.  Once the contents of the $\next$ block are
speculated into a residual ($q$), the output of $\redonesym$ is a fresh variable wrapped in a
$\next$ block ($\next~\hat y$), along with a future environment which maps that
variable to the residual ($\hat y \mapsto q$).

At all of the normal features (\ref{fig:diaSemanticsSpec}), speculation does
nothing but recursively speculate into every subexpression.  Once speculation
finds a $\prev$ block, it resumes stage \bbone\ evaluation of the contents, which
produces a future context and (by canonical forms) a $\next$-wrapped variable
($\next\{\hat y\}$).  The context is then reified (using the $\reifysym$
judgment) into a series of let bindings with $\mathtt{\hat y}$, stripped of
its $\next$, at the bottom.

Within speculation lies a subtle---if perhaps unintuitive---feature.  
Observe that speculation will traverse into both branches of a stage-\bbtwo\ {\tt if} or {\tt case} 
statement in its search for stage-\bbone\ code. 
Thus the evaluation of that stage one code will occur {\em regardless of the eventual value of the predicate},
and so a term like 
\begin{lstlisting} 
next{
  if true 
  then hold{1+2} 
  else prev{spin() (* loops forever *)}
}
\end{lstlisting}
will fail to evaluate at stage \bbone.
This behavior is why the judgment is named ``speculation."

The context ($\Gamma$) keeps track of stage \bbtwo\ variables in the input term. 
These both appear in the original program at stage \bbtwo\ and are inserted by the semantics.

As an optimization, we can include the special-case rule,
\begin{mathpar}
\inferdiaone [hat] {\red {\next~\hat y}{\cdot,\next~\hat y}}{\cdot}
\end{mathpar}
to avoid one-for-one variable bindings in the residual.
We used this implicitly in the example in the previous section.

If we change the $\next$ and $\prev$ rules to 
\begin{mathpar}
\infer {\diaone {\next~e}{\cdot,\next~q}} {\diatwo e q} \and
\infer {\diatwo{\prev~e}{v}} {\diaone e {\cdot,\next~v}} 
\end{mathpar}
and treat $\next~q$ as a partial value for any residual $q$,
then our semantics becomes rule-for-rule isomorphic to that from \cite{davies96}. This essentially bypasses the
environment bookkeeping in $\redonesym$, by inlining residuals instead of
hoisting them in \verb|let|-bindings.
From this it's clear that the semantics of \cite{davies96} and ours always produce the same value when they both terminate.
{\em Because \lang's semantics dictate that a reified residual will always be evaluated, regardless of whether its result is consumed, \lang\ programs terminate strictly less often than that of \cite{davies96}}.

Returning to our {\tt fexp} example, we can speculate on the stage \bbtwo\ term
$\verb|fn b => prev{fexp(next{b},10)}|$
to get the residual
\begin{lstlisting} 
fn b : int =>
  let x0 =
    (let x1 = 
      let x2 = 1 * b
      in x2 * x2
    in x1 * x1) * b
  in x0 * x0
\end{lstlisting}

Note how the recursion causes duplicate code in the residual.

\subsection {A Partial Evaluation System}
\label{sec:partialeval}

The dynamics described in the previous section provide a formal description of partial evaluation.
Recall that in partial evaluation systems, we start with a multivariate function $f$ for which some input is labeled {\em static} and 
some labeled {\em dynamic}.  Once the static input is provided, partial evaluation of $f$ produces
a residual that depends on only the dynamic input.  Equationally, a partial evaluator is any $p$ such that
\[
	\forall f,x. \exists f_x. [p(f,x) = f_x \text{ and } \forall y.\llbracket f \rrbracket(x,y)=\llbracket f_x \rrbracket(y)]
\]
where $\llbracket \cdot \rrbracket$ translates the text of a function to it's mathematical interpretation (a la \cite{jones96}).
Here, $x$ is the static input, $y$ is the dynamic input, and $f_x$ is the residual, also called ``f specialized to x."

% KAYVONF: good statement, but hold out for now
%The hope of partial evaluation is that $f_x$ is cheaper to execute than $f$, meaning that we can save work if we must %evaluate it many times.

By identifying static with stage \bbone\ and dynamic with stage \bbtwo, 
our dynamics can serve as a partial evaluator.   
Specifically, we encode $f$ as a \lang\ expression with a function type of the form $A\to\fut(B\to C)$
\cprotect\footnote{We can rewrite \texttt{fexp} in this form, or simply apply
the following higher-order function which makes the adjustment:
\begin{lstlisting} 
let adjust (f : $int * int -> $int) =
  fn (p : int) => 
    next{
      fn (b : int) => 
        prev{f (next {b}, p)}
    }
\end{lstlisting}}.
%
Here $A$ represents the static input, $B$ represents the dynamic input, and $C$ represents the output.

Once a stage \bbone\ argument $a:A$ is provided, we can evaluate the partially-applied
function:
$\cdot\vdash f~a \mathop{\redonesym} [\xi,v]$.
The result is an environment $\xi$ and a partial value $v$ of type $\fut(B\to
C)$, which by canonical forms must have the form $v = \next~\hat y$. 
Next, we reify this environment into a sequence of \verb|let|-bindings
enclosing $\hat y$, via $\reify\xi{\hat y}{f_a}$. 
Because reification preserves types, the resulting residual $f_a$ has type $B\to C$ in \langTwo, so we can apply it to some $b:B$
and compute the final result of the function, $f_a~b \mathop{\tworedsym} c$.

That this sequence of evaluations is in fact staged follows from our
characterizations of partial values, residuals, and values, that $\redonesym$
outputs a partial value, and that $\reifysym$ outputs an expression in \langTwo.

%\begin{remark}
%For any $\colone{e}{A}$ containing no $\next$ subexpressions, $\redonesym$ will
%always compute an empty environment, and a partial value identical to the result
%of call-by-value evaluation of $e$.
%%derivationally equivalent to standard call-by-value evaluation.
%\end{remark}

%\subsection{Metatheory}
%
%Recall that residuals live in \langTwo; we will indicate typing judgments in
%\langTwo\ with $\vdash_\bbtwo$.
%
%%\begin{definition}
%%Context $\Gamma$ is well-formed ($\Gamma\wf$) if it
%%contains only stage-2 variables.
%%\end{definition}
%
%\begin{definition}
%An environment $\xi$ is well-formed ($\Gamma\vdash\xi\wf$) if either:
%\begin{enumerate}
%\item $\xi = \cdot$; or
%\item $\xi = \xi',x:B\mapsto e$ where
%$\Gamma\vdash\xi'\wf$ and
%$\typeslangTwo[\Gamma,\dom{\xi'}] e B$
%%$\Gamma,\dom{\xi'}\vdash \coltwo{e}{B}$ and
%%$\Gamma,\dom{\xi'}\vdash e \res$.
%\end{enumerate}
%\end{definition}
%
%\begin{theorem}
%If $\typeswor e A$ then $\Gamma\wf$ and $A\istypewor$.
%\end{theorem}
%
%\begin{theorem}
%If $\diaonesub$ and $\typesone e A$ then
%\begin{enumerate}
%\item $\Gamma\vdash\xi\wf$;
%\item $\Gamma,\dom\xi\vdash \colone{v}{A}$; and
%\item $\Gamma,\dom\xi\vdash v\pval$.
%\end{enumerate}
%\end{theorem}
%
%\begin{theorem}
%If $\diatwosub$ and $\typestwo e A$ then
%\begin{enumerate}
%\item $\typeslangTwo q A$; and
%\item $\Gamma\vdash_\bbtwo q\val$.
%\end{enumerate}
%\end{theorem}
%
%\begin{theorem}\label{thm:reify-type}
%If $\Gamma\vdash\xi\wf$ and
%$\Gamma,\dom\xi\vdash \colone{\next\ \hat y}{\fut A}$
%then 
%$\reify{\xi}{\hat y}{q}$ and
%$\typeslangTwo q A$.
%\end{theorem}

%\TODO
%Note somewhere how to run stage-one non-$\fut A$ terms. For example, a stage-one
%integer term is guaranteed not to depend on the table, although one might be
%produced. One may either discard the table, or evaluate everything in the table
%(and terminating with the partial value iff everything in the table terminates).


