\section {The \lang\ Language}

\begin{figure*}
\begin{subfigure}{0.5\textwidth}
\begin{lstlisting} 
datatype list = Empty | Cons of int * list
fun partition (p : int, l : list) 
  : (int*list*list) =
  case unroll l of 
    Empty => (0,Empty, Empty) 
  | Cons (h,t) =>
      let (s,left,right) = partition (p,t) in
      if h<p 
      then (s+1,Cons(h,left),right)
      else (s,left,Cons(h,right))

fun qs (l : list, i : int) : int = 
  case l of
    Empty => next {0}
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
        case compare i n of
          LT => qs left i
        | EQ => h
        | GT => qs right (i-n-1)
\end{lstlisting}
\caption{Unstaged Code}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\begin{lstlisting} 
datatype list = Empty | Cons of int * list

fun partition (p : int, l : list) = ...
fun qs (l : list, i: $int) : $int = 
  case l of
    Empty => next {0}
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
      next{
        let n = hold{n} in
          case compare prev{i} n of
            LT => prev {qs left i}
          | EQ => hold {h}
          | GT => prev {qs right next{prev{i}-n-1}}
      }	
\end{lstlisting}
\caption{Staged Code}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\begin{lstlisting} 
datatype list = Empty | Cons of int * list
fun partition (p : int, l : list) = ...
	
datatype tree = Branch of int * int * tree * tree
                | Leaf

fun qs1 (l : list) : tree =
  case l of
    Empty => Leaf
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
      Branch (n, h, qs1 left i, qs1 right i)

fun qs2 (p : tree, i : int) : int = 
  case unroll p of
    Leaf => 0
  | Branch (n,h,p1,p2) => 
      case compare i n of
        LT => qs2 (p1,i)
      | EQ => h
      | GT => qs2 (p2,i-n-1)
\end{lstlisting}
\caption{Split Code}
\end{subfigure}
\caption{Caption place holder}
\end{figure*}

Consider the quickselect algorithm in [the figure],
which finds the $i$th largest element of a list.
It operates by inspecting the head of the list, 
partitioning the rest of the list by the head,
comparing the size of the partition to the desired index,
and the recursively selecting on the correct sublist.
If the index was outside valid bounds, 0 is returned.
[runtime]

It has been observed that [dependency...].

We can then leverage this dependency to split quickselect into two other functions [one precomputes all splits... build tree... other consumes].
[We've shown this in figure...]
[we like it as two functions because... multiple calls... efficient]

The goal of our work is to do this transformation automatically.
[first we need a language to ... unambiguously and clearly specify staging]
[ideally that language looks similar to the original term]
[The type system for this language should be enough to prove that splitting will work out.]

[to this end, we present \lang]
The main idea of \lang\ is that terms defined in it are 
split across two {\em stages}, called \bbone\ and \bbtwo.
If part of the term is in \bbone, then it will end up in the precomputation, else it will end up in the residual.
[information can flow from the stage \bbone\ portions of the term to the stage \bbtwo\ portions,
but never from \bbtwo\ to \bbone.  this property is required if we want to be able to split the term]

[Check out the example, now staged all fancy.]

This staged version contains three new constructs: 
$\next$ and $\prev$ at the term level, and $\fut$ at the type level.
We can read $\next$ and $\prev$ as indications to 
execute the code in the following block at stage \bbtwo\ and \bbone, respectively.
The type constructor $\fut$ is a way for us to talk at stage \bbone\ about things that will not be available until stage \bbtwo.
Thus, ${\tt fexp} : \fut\rmint \times \rmint \to \fut\rmint$ 
can be read as a function that takes a base at stage \bbtwo\ and a power at stage \bbone, 
and returns the exponent at stage \bbtwo.

[$\fut$ acts in a sanitary way]

\section{Statics and Dynamics}
\label{sec:semantics}

\input {figures/grammars}
\input {figures/statics}
%
\footnote{It is possible for different stages to have different sets of
features, but for simplicity we do not consider this.}
Every valid expression has both a type and a stage, either \bbone~or \bbtwo,
expressing in which copy of the language the term resides. Intuitively, the
stage of a term expresses \emph{when} to evaluate it---all stage-\bbone\
subexpressions are evaluated before stage-\bbtwo\ ones.

The stage-\bbone\ type $\fut A$ contains encapsulated
stage-\bbtwo\ expressions of type $A$. Terms of type $\fut A$ are treated
opaquely by stage-\bbone\ code, as (by the requirements of staging) they cannot be evaluated until stage \bbtwo.
While $\fut$ allows us to embed stage-\bbtwo\ types within stage-\bbone\ types,
there is no way to embed a stage-\bbone\ type within a stage-\bbtwo\ type.
That is, there is a one-way dependence between stages at the term level.

Alternatively, the stages are mutually dependent at the term level.
The $\next$ constructor embeds stage-\bbtwo\ expressions into stage \bbone,
while $\prev$ embeds stage-\bbone\ expressions into stage \bbtwo.  $\next$ and $\prev$ are the
only ways in \lang\ to alter the stage of a term; we surround their arguments
with braces in \lang\ syntax to clearly indicate stage boundaries within a
program.

The grammar and type system for \lang\ is given in \ref{fig:grammar,fig:statics}. 
Typing judgments and context variables are annotated with stages after an $@$ symbol.
Only $\fut$ and its introductory and eliminatory forms $\next$ and $\prev$ affect the stage
of a term or type.
%We formulated our typing judgments in the style of \cite{davies96}, where the
%whole judgment is annotated with a stage.  
%The grammar and type system for \lang\ is given in
%\ref{fig:grammar,fig:statics}.
% We annotate typing judgments and context variables with stages;
%This is made manifest as rules which are entirely abstract over stage.
%In addition to determining the stage, $\next$ and $\prev$ are the introduction and elimination forms for $\fut$ types.
Specifically, given an argument with type $A$ at stage \bbtwo, $\next$ forms a $\fut A$ at stage \bbone.  
%That is, it forms the promise of a future $A$ out of a construction for an $A$ at the next timestep.
Stage \bbtwo\ expressions can obtain the original stage \bbtwo\ argument via the $\prev$ construct.  
Since $\prev$ operates at stage \bbtwo, this ensures no violation of causality,\cite{cave14}.
The $\pause$ construct serves to wrap stage \bbone\ integers for use in stage \bbtwo.  
It is possible to implement $\pause$ from other \lang\ features, but
we provide it as a core primitive to simplify our examples. 

Recall the fast exponent function from above.
We present a valid staging of it here:
\begin{lstlisting} 
let fexp (b : $int, p : int) : $int =
	if p == 0 then
		next{1}
	else if (p mod 2) == 0 then
		next{let x = prev{fexp(b,p/2)} in x*x}
	else
		next{prev{b} * prev{fexp(b,p-1)}}		
\end{lstlisting}

\TODO explain why we staged this the way we did

The function receives a stage-\bbone\ exponent {\tt e} and a stage-\bbtwo\ base {\tt b} and returns a stage-\bbtwo\ result. 
The {\tt if} predicates and exponent decomposition are all stage-\bbone\ terms, since they occur within $\prev$ blocks.

\subsection{Staged Evaluation}
\label{sec:stagedsemantics}

A key attribute of the fexp example is that stage-\bbone\ and stage-\bbtwo\ expressions are nested. 
Ordinary term evaluation eliminates outermost redexes first, 
however in the case that stage \bbone\ expressions are contained inside stage \bbtwo\ ones 
(such as the recurive call to {\tt fexp} above), 
this strategy conflicts with the precept of staged execution: 
that all stage-\bbone\ code be evaluated before the evaluation of stage-\bbtwo\ code. 

Thus, our dynamic semantics for \lang\ evaluates all of a term's stage \bbone\
subexpressions before any of its stage \bbtwo\ subexpressions. This results in a
stage \bbtwo\ term with no stage \bbone\ content; we say this is a term in a
monostaged
\footnote{In general, \lang could have more than two stages, in which case the
expression would be in a language with one fewer stage.}
language called \langTwo. Then, we perform the remainder of the evaluation with 
$\tworedsym$, an ordinary dynamic semantics for \langTwo\ (the rules for this
judgment are not shown, but they are standard).

\subsection{Non-Duplicating First-Stage Evaluation}

To gain intuition about the challenges of implementing this staged dynamic
semantics, consider the following example:
\begin{lstlisting}
#2 (next {fib 20}, 2+3)
\end{lstlisting}
This is a stage-\bbone\ expression of type $\rmint$; the pair inside it is a
stage-\bbone\ expression of type $(\fut\rmint)\times\rmint$. 
In this example, ${\tt fib} : \rmint \to \rmint$ is a stage-\bbtwo\ reference to the Fibonacci function.
A conventional call-by-value evaluation strategy demands that we evaluate both components of
the pair to values before we project from the pair. The problem is that
while \verb|next {fib 20}| is not a value (in the sense that additional
stage-\bbtwo\ computation steps are necessary to produce the result \verb|6765|), 
evaluating the contents of \verb|next| cannot occur as part of stage-\bbone\ evaluation.
Intuitively, the solution is to designate \verb|next {fib 20}| as a value \emph{in
stage \bbone}, even though it requires additional evaluation in stage \bbtwo.
Therefore, we evaluate the pair to
\begin{lstlisting}
#2 (next {fib 20}, 5)
\end{lstlisting}
then obtain \verb|5| as the result of projection.

Now consider a more complex example where 
stage-\bbone\ evaluation must substitute such a incompletely-evaluated
expression. The following stage-\bbtwo\ term has type $\rmint$:
\begin{lstlisting} 
prev{
  let x = (next {fib 20}, 3+4) in
  next{ prev{#1 x} * prev{#1 x} * hold{#2 x} }
}
\end{lstlisting}
Again, stage-\bbone\ evaluation will not fully reduce this term, because the answer
depends on the value of \verb|fib 20|, which is not reduced to \verb|3| until
stage \bbtwo.

If we simply treat \verb|(next {fib 20}, 7)| as a value during stage~\bbone, and
substitute it for the three occurrences of \verb|x| in the body of the
\verb|let| expression, the result of stage \bbone\ computation is
\begin{lstlisting} 
prev{
  next{ 
    prev{next {fib 20}} * prev{next {fib 20}} * 7 
  }
}
\end{lstlisting}
Finally, the $\prev$s eliminate the $\next$s to yield the final residual:
\begin{lstlisting} 
(fib 20) * (fib 20) * 7
\end{lstlisting}
Note how stage-\bbtwo\ evaluation of this expression will compute \verb|fib 20| twice.  
To avoid duplicating computations, we take a different approach.  Instead of
duplicating the contents of the $\next$ expression in the tuple, we bind the contained stage-\bbtwo\ expression to
a variable (here, $\mathtt{y}$) and duplicate only a reference to that variable.
This produces:
\begin{lstlisting} 
let y = fib 20 in y * y * 7
\end{lstlisting}

Achieving this behavior mechanically requires us to resolve a contradiction:
we must substitute for \texttt{x} in stage \bbone, but we cannot evaluate inside the $\next$ block within the tuple. 
Our solution is to replace the contents of the $\next$ with a new stage-\bbtwo\ variable and create an explicit substitution (shown with a $\mapsto$) binding that stage-\bbtwo\ variable to the $\next$'s old contents.  
This substitution then floats up to the top of the containing $\prev$ block:
\begin{lstlisting} 
prev {
[yhat|->fib 20]
  let x = (next{yhat}, 7) in
  next{prev{#1 x} * prev{#1 x} *  hold{#2 x}}
}
\end{lstlisting}
As a convention, we render the new variable with a %stylish and fashionable
hat.  We're now free to perform the stage-\bbone~substitution for {\tt x} without duplicating stage-\bbtwo\ work.
\begin{lstlisting} 
prev {
[yhat|->fib 20]
  next{
    prev{#1 (next {yhat}, 7)} * 
    prev{#1 (next {yhat}, 7)} *
    hold{#2 (next {yhat}, 7)}
  }
}
\end{lstlisting}
To evaluate the outermost $\next$, we must first partially evaluate within its body by finding all of the contained stage-\bbone~terms and reducing them. 
As a rule, these will reduce to $\next$ expressions, which the $\prev$ eliminates, leaving the variable in place:
\begin{lstlisting} 
prev {
[yhat|->fib 20]
    next{ yhat * yhat * 7 }
}
\end{lstlisting}
Once again, we lift the contents of the $\next$ into a substitution:
\begin{lstlisting} 
prev {
[yhat|->fib 20]
[zhat|->yhat*yhat*7]
    next{ zhat }
}
\end{lstlisting}
Finally, when evaluating the outer $\prev$, we must {\em reify} the contained substitutions into let statements, yielding
\begin{lstlisting} 
let yhat = fib 20 in
let zhat = yhat * yhat * 7 in z
\end{lstlisting}

Thus we have evaluated all of the stage \bbone\ expressions of this program without duplicating the contents of $\next$ blocks.

\subsection{Dynamics}
\label{ssec:dynamics}

\input {figures/dynamics}

The algorithm described above creates three different kinds of expressions which
cannot be evaluated further at a particular stage:
\begin{itemize}
\item 
Partial values ($\pvalsym$s) are stage \bbone\ terms that have been fully evaluated, 
but which may contain stage-\bbtwo\ variables wrapped in $\next$ blocks. 
In the example above, 
\verb|(|$\next \{\mathtt{\hat y}\}$\verb|,7)|.

\item Residuals ($\ressym$es) are \langTwo\ terms---stage \bbtwo\ terms whose
stage \bbone\ subexpressions have all been fully evaluated. In the example
above,
\verb|(1+2)| and \verb|(let z = y*y*7 in z)|.

\item Values ($\valsym$s) are \langTwo\ terms which are fully evaluated; these
are the results of a computation after both stages have been completed. In the
example above, the term evaluates to \verb|63|.
\end{itemize}

% would like some kind of intro here that anticipates all the complexity.
% The dynamics of \lang\ consists of three types of judgements: $\redonesym$ (stage-\bbone reduction), $\redtwosym$ (speculation), and $\reifysym$ (reification).

The $\redonesym$ judgment takes an open stage \bbone\ term to a {\em future
environment} $\xi$ and a partial value $v$.  The future environment is a mapping
from fresh stage \bbtwo\ variables (which may appear inside $\next$ blocks in
$v$) to residuals---in our example above, we represented this environment with
explicit substitutions. For all of the normal features of \lang\ 
(\ref{fig:diaSemanticsCore}), first stage evaluation has the same behavior and
effect on (partial) values as does standard evaluation, and the final future environment is
gotten by merging the future environments of the subterms.

When the \bbone\ judgment encounters a $\next$ block (\ref{fig:diaSemanticsNP}), it
searches into the block's stage \bbtwo\ content to find any contained stage
\bbone\ subexpressions and evaluate them in place.  This search process, called
\emph{speculation}, is implemented by the $\redtwosym$ judgment, which takes
a stage \bbtwo\ term to a residual.  Once the contents of the $\next$ block are
speculated into a residual ($q$), the output of $\redonesym$ is a fresh variable wrapped in a
$\next$ block ($\next~\hat y$), along with a future environment which maps that
variable to the residual ($\hat y \mapsto q$).

At all of the normal features (\ref{fig:diaSemanticsSpec}), speculation does
nothing but recursively speculate into every subexpression.  Once speculation
finds a $\prev$ block, it resumes stage \bbone\ evaluation of the contents, which
produces a future context and (by canonical forms) a $\next$-wrapped variable
($\next\{\hat y\}$).  The context is then reified (using the $\reifysym$
judgment) into a series of let bindings with $\mathtt{\hat y}$, stripped of
its $\next$, at the bottom.

Within speculation lies a subtle---if perhaps unintuitive---feature.  
Observe that speculation will traverse into both branches of a stage-\bbtwo\ {\tt if} or {\tt case} 
statement in its search for stage-\bbone\ code. 
Thus the evaluation of that stage one code will occur {\em regardless of the eventual value of the predicate},
and so a term like 
\begin{lstlisting} 
next{
  if true 
  then hold{1+2} 
  else prev{spin() (* loops forever *)}
}
\end{lstlisting}
will fail to evaluate at stage \bbone.
This behavior is why the judgment is named ``speculation."

The context ($\Gamma$) keeps track of stage \bbtwo\ variables in the input term. 
These both appear in the original program at stage \bbtwo\ and are inserted by the semantics.

As an optimization, we can include the special-case rule,
\begin{mathpar}
\inferdiaone [hat] {\red {\next~\hat y}{\cdot,\next~\hat y}}{\cdot}
\end{mathpar}
to avoid one-for-one variable bindings in the residual.
We used this implicitly in the example in the previous section.

If we change the $\next$ and $\prev$ rules to 
\begin{mathpar}
\infer {\diaone {\next~e}{\cdot,\next~q}} {\diatwo e q} \and
\infer {\diatwo{\prev~e}{v}} {\diaone e {\cdot,\next~v}} 
\end{mathpar}
and treat $\next~q$ as a partial value for any residual $q$,
then our semantics becomes rule-for-rule isomorphic to that from \cite{davies96}. This essentially bypasses the
environment bookkeeping in $\redonesym$, by inlining residuals instead of
hoisting them in \verb|let|-bindings.
From this it's clear that the semantics of \cite{davies96} and ours always produce the same value when they both terminate.
{\em Because \lang's semantics dictate that a reified residual will always be evaluated, regardless of whether its result is consumed, \lang\ programs terminate strictly less often than that of \cite{davies96}}.

Returning to our {\tt fexp} example, we can speculate on the stage \bbtwo\ term
$\verb|fn b => prev{fexp(next{b},10)}|$
to get the residual
\begin{lstlisting} 
fn b : int =>
  let x0 =
    (let x1 = 
      let x2 = 1 * b
      in x2 * x2
    in x1 * x1) * b
  in x0 * x0
\end{lstlisting}

Note how the recursion causes duplicate code in the residual.

\subsection {A Partial Evaluation System}
\label{sec:partialeval}

The dynamics described in the previous section provide a formal description of partial evaluation.
Recall that in partial evaluation systems, we start with a multivariate function $f$ for which some input is labeled {\em static} and 
some labeled {\em dynamic}.  Once the static input is provided, partial evaluation of $f$ produces
a residual that depends on only the dynamic input.  Equationally, a partial evaluator is any $p$ such that
\[
	\forall f,x. \exists f_x. [p(f,x) = f_x \text{ and } \forall y.\llbracket f \rrbracket(x,y)=\llbracket f_x \rrbracket(y)]
\]
where $\llbracket \cdot \rrbracket$ translates the text of a function to it's mathematical interpretation (a la \cite{jones96}).
Here, $x$ is the static input, $y$ is the dynamic input, and $f_x$ is the residual, also called ``f specialized to x."

% KAYVONF: good statement, but hold out for now
%The hope of partial evaluation is that $f_x$ is cheaper to execute than $f$, meaning that we can save work if we must %evaluate it many times.

By identifying static with stage \bbone\ and dynamic with stage \bbtwo, 
our dynamics can serve as a partial evaluator.   
Specifically, we encode $f$ as a \lang\ expression with a function type of the form $A\to\fut(B\to C)$
\cprotect\footnote{We can rewrite \texttt{fexp} in this form, or simply apply
the following higher-order function which makes the adjustment:
\begin{lstlisting} 
let adjust (f : $int * int -> $int) =
  fn (p : int) => 
    next{
      fn (b : int) => 
        prev{f (next {b}, p)}
    }
\end{lstlisting}}.
%
Here $A$ represents the static input, $B$ represents the dynamic input, and $C$ represents the output.

Once a stage \bbone\ argument $a:A$ is provided, we can evaluate the partially-applied
function:
$\cdot\vdash f~a \mathop{\redonesym} [\xi,v]$.
The result is an environment $\xi$ and a partial value $v$ of type $\fut(B\to
C)$, which by canonical forms must have the form $v = \next~\hat y$. 
Next, we reify this environment into a sequence of \verb|let|-bindings
enclosing $\hat y$, via $\reify\xi{\hat y}{f_a}$. 
Because reification preserves types, the resulting residual $f_a$ has type $B\to C$ in \langTwo, so we can apply it to some $b:B$
and compute the final result of the function, $f_a~b \mathop{\tworedsym} c$.

That this sequence of evaluations is in fact staged follows from our
characterizations of partial values, residuals, and values, that $\redonesym$
outputs a partial value, and that $\reifysym$ outputs an expression in \langTwo.

%\begin{remark}
%For any $\colone{e}{A}$ containing no $\next$ subexpressions, $\redonesym$ will
%always compute an empty environment, and a partial value identical to the result
%of call-by-value evaluation of $e$.
%%derivationally equivalent to standard call-by-value evaluation.
%\end{remark}

%\subsection{Metatheory}
%
%Recall that residuals live in \langTwo; we will indicate typing judgments in
%\langTwo\ with $\vdash_\bbtwo$.
%
%%\begin{definition}
%%Context $\Gamma$ is well-formed ($\Gamma\wf$) if it
%%contains only stage-2 variables.
%%\end{definition}
%
%\begin{definition}
%An environment $\xi$ is well-formed ($\Gamma\vdash\xi\wf$) if either:
%\begin{enumerate}
%\item $\xi = \cdot$; or
%\item $\xi = \xi',x:B\mapsto e$ where
%$\Gamma\vdash\xi'\wf$ and
%$\typeslangTwo[\Gamma,\dom{\xi'}] e B$
%%$\Gamma,\dom{\xi'}\vdash \coltwo{e}{B}$ and
%%$\Gamma,\dom{\xi'}\vdash e \res$.
%\end{enumerate}
%\end{definition}
%
%\begin{theorem}
%If $\typeswor e A$ then $\Gamma\wf$ and $A\istypewor$.
%\end{theorem}
%
%\begin{theorem}
%If $\diaonesub$ and $\typesone e A$ then
%\begin{enumerate}
%\item $\Gamma\vdash\xi\wf$;
%\item $\Gamma,\dom\xi\vdash \colone{v}{A}$; and
%\item $\Gamma,\dom\xi\vdash v\pval$.
%\end{enumerate}
%\end{theorem}
%
%\begin{theorem}
%If $\diatwosub$ and $\typestwo e A$ then
%\begin{enumerate}
%\item $\typeslangTwo q A$; and
%\item $\Gamma\vdash_\bbtwo q\val$.
%\end{enumerate}
%\end{theorem}
%
%\begin{theorem}\label{thm:reify-type}
%If $\Gamma\vdash\xi\wf$ and
%$\Gamma,\dom\xi\vdash \colone{\next\ \hat y}{\fut A}$
%then 
%$\reify{\xi}{\hat y}{q}$ and
%$\typeslangTwo q A$.
%\end{theorem}

%\TODO
%Note somewhere how to run stage-one non-$\fut A$ terms. For example, a stage-one
%integer term is guaranteed not to depend on the table, although one might be
%produced. One may either discard the table, or evaluate everything in the table
%(and terminating with the partial value iff everything in the table terminates).


