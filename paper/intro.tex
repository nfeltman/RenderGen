\section{Introduction}

\crem{Notes from 2/21:
\begin{enumerate}
\item see K/R intro.
\item function specialization is an important optimization technique which can
be performed whether or not the function's arguments are known.
\item data specialization statically specializes a multi-argument program
\emph{before} having any of its arguments, unlike partial evaluation.
\item we are doing data specialization, but on lambda calculus (cf C-like
languages, as in graphics papers).
\item this additional expressive power gives us some interesting
results---asymptotic speedup on some algorithms (and generation of recursive
types from recursive functions), and cross-cutting (?) modularity (see graphics
applications).
\end{enumerate}
}

\subsection{Old intro}

partial evaluation requires compile-time access to first stage, whereas we don't

Prior work on metaprogramming allows us to evaluate such staged code
in a staged fashion by first providing the first-stage arguments and
generating a piece of code that is specialized for the arguments.  For
example, we can evaluate the staged quickselect by providing a
list~\texttt{l} to obtain a piece of code that then can be used with
different ranks (\texttt{k} values) in the second stage.
Such a specialized code essentially performs all the first-stage computations
first and uses their results to improve the efficiency in the second stage,
where we issue many queries.  

For example, in our quickselect example, it is unlikely to know the
list~\texttt{l} that we will be operation on at compile time. 

\cite{knoblock96} proposed the {\em data specialization}
technique to overcome some of these limitations of program
specialization.  
Unlike program specialization,
data specialization does not require knowledge of the first-stage
arguments to produce fast code for the second stage.  
Instead it yield
a first stage program that maps the first stage arguments to an
intermediate or {\em boundary data structure}, which is used by the
second stage program along with the second stage arguments to produce
the final results.  

But their work applies to program fragments that don't involve sophisticated
data types such as as sums and recursive types, and don't involve recursion.

\subsection{Oldest intro}

This most often arises when
we want to evaluate a multivariate function several times, with some inputs
dynamic (varying across invocations) and some static (constant across
invocations).
\begin{itemize}
\item Computing $b^e$, where $b$ varies and $e$ is constant.
\item Finding the $i$th largest element in a list, where the list is constant
and $i$ varies.
\item Computing the shading of a surface in a 3D rendering, where some
contributors to the final pixel color can be approximated as constant over
pixel blocks.  
\end{itemize}
Prior examples
include the ``data specialization" work of Knoblock and Ruf~\cite{knoblock96}
as well as the compilation of high-level shading languages for computer graphics
such as RTSL~\cite{Proudfoot:2001} and Spark~\cite{Foley:2011}.

Recall that partial evaluators operate on multivariate functions $f$, whose
inputs are each labeled either {\em static} or {\em dynamic}. Once the static
inputs are provided, partial evaluation of $f$ produces a residual depending on
only the dynamic input. Mathematically, a partial evaluator is any $p$ such that
\[
	\forall f,x. \exists f_x. \left[p(f,x) = f_x \text{ and } \forall y.\llbracket f \rrbracket(x,y)=\llbracket f_x \rrbracket(y)\right]
\]
where $\llbracket \cdot \rrbracket$ translates the text of a function to its
mathematical interpretation (a la \cite{jones96}). Here, $x$ is the static
input, $y$ is the dynamic input, and $f_x$ is the residual, that is, \emph{$f$
specialized to $x$}.

Taking a multivariate function $f$ as input, stage-splitting produces two
functions $f_1$ and $f_2$, where $f_1$ uses the stage-\bbone\ input to produce a
data structure, and $f_2$ consumes that data structure and the stage-\bbtwo\
input to produce the final output.  More precisely, a stage splitter is any $s$
such that
\[
	\forall f. \exists f_1,f_2. 
	\left[
		\begin{array}{l}
		s(f) = (f_1,f_2) \text{ and } \\
		\forall x,y.\llbracket f \rrbracket(x,y)=\llbracket f_2 \rrbracket(\llbracket f_1 \rrbracket(x),y)
		\end{array}
	\right]
\]
with the same $\llbracket \cdot \rrbracket$ notation as before.
The stage splitting operation does not depend on the stage-\bbone\ input.
This stands in contrast to the definition of partial evaluation, where $f_x$ does depend on $x$.

\Cref{sec:semantics} describes the grammar and type system of \lang, as well as
a reference semantics which is essentially a partial evaluator that respects
staging. \Cref{sec:splitting} describes a stage-splitting transformation for
\lang\ and proves its equivalence to the reference semantics.  Finally,
\Cref{sec:examples} gives several examples of how stage-splitting terms in
\lang\ can be used to derive classic data structures, and discusses the
effectiveness and limitations of this technique.  Notably, these examples make
use of the stage-splitting features not available in prior work.


