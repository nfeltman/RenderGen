\section{Splitting Algorithm}
\label{sec:splitting}

Given a term $e$ in the source language \lang, where terms of
stage~\bbone\ and stage~\bbtwo\ may be interleaved, \emph{(stage)
  splitting} separates the stage~\bbone\ and stage~\bbtwo\
subcomputations into two terms, $e_1$ and $e_2$, in an unstaged target language \langmono\ 
%each performing the
%subcomputations corresponding to each stage.  More precisely, given a
%\lang\ term~$e$, splitting yields two terms $e_1$ and $e_2$ in a
%unstaged target language \langmono\
such that~$e_1$ performs all the
stage~\bbone\ subcomputations in~$e$ and $e_2$~performs all of the
stage~\bbtwo\ subcomputations. Splitting preserves correctness in the sense that evaluation of~$e$ in
the staged language produces the same result as evaluating~$e_1$, followed by evaluating 
$e_2$ with the result from~$e_1$.

In this section, we present a
splitting algorithm for the source language \lang, specifying
precisely the algorithm and its correctness conditions.  
We begin by defining a masking relation that serves to extract stage~\bbone\ and
stage~\bbtwo\ components of \lang\ partial values into \langmono\ terms that the outputs of splitting must match. We then 
move on to the specification of the splitting algorithm itself.


\subsection{Partial Value Masking}

% Intuitively, we require that the terms obtained by splitting a term $e$, when
% evaluated, agree with $e$ when evaluated according to our dynamic semantics. In
% the case of stage~\bbone\ terms, our dynamic semantics produce partial values
% containing information at \emph{both} stages, which goes against the idea that
% splitting separates the subcomputations belonging to each stage.

Recall that \lang\ partial values and residual tables together may
contain content at \emph{both} stages. For example the term:
\begin{lstlisting}
1`(1+2, next{`2`hold{`1`3+4`2`} + 5`1`})`
\end{lstlisting}
evaluates via $\redonesym$ to:
\begin{lstlisting}
2`[yhat|->7+5]` 1`(3,next{`2`yhat`1`})`
\end{lstlisting}
Intuitively, splitting this term should generate an $e_1$ that reduces to the stage 1 content of the partial value (3), and an $e_2$ corresponding to the stage~\bbtwo\
computation $\letin \yhat {\mathtt{7+5}} \yhat$.

To precisely define the stage~\bbone\ and stage~\bbtwo\ components of the partial value, we define 
\emph{partial-value masking} (or simply {\em masking}) functions, written $\masko{{-}}$ and $\maskt{{-};{-}}$, 
which take a residual table and partial value as input and emit a term in \langmono\
that corresponds to only the content belonging to a single stage. \ref{fig:valMask} defines these
masking functions.

\emph{Stage~\bbone\ masking} of the partial value $v$ (written $\masko{v}$) produces a term in \langmono\ containing exactly
the stage~\bbone\ content of $v$. Since \next\ terms only contain stage~\bbtwo\
content, $\masko{v}$ replaces all $\next$ subterms of $v$ with \texttt{()}.  Since lambdas may represent multi-stage computations, stage~\bbone\ masking splits their bodies as general stage~\bbone\ terms (as described in \ref{sec:split-one}), and returns
the stage~\bbone\ component. $\masko{v}$ always produces a value in \langmono\ that has
the same structure as~$v$.  For example, the stage~\bbone\ mask of the partial value given above is \texttt{(3,())}. 

\emph{Stage~\bbtwo\ masking} of the partial value $v$ and residual context $\xi$ (written $\maskt{\xi;v}$) produces a term in \langmono\ containing
exactly the stage~\bbtwo\ content of $[\xi;v]$. Unlike stage~\bbone\ masking, stage~\bbtwo\ masking 
requires access to the residual table $\xi$ because all stage~\bbtwo\
content in $v$ has been lifted out into $\xi$. Stage~\bbtwo\ masking discards
stage~\bbone\ content in $v$ by replacing base constants with~\texttt{()},
replacing $\next~\hat{y}$ with~$\hat{y}$, and replacing all $n$-ary term
constructors with an $n$-tuple of masked subterms. Like stage~\bbone\ masking, stage~\bbtwo\
masking splits the bodies of lambdas as general stage~\bbone\ terms, and
returns the stage~\bbtwo\ component. After discarding all stage~\bbone\ content from $v$, stage~\bbtwo\ masking reifies $\xi$ around the result,
producing a term in \langmono. For example, the stage~\bbtwo\ mask of the partial value and residual table given above is:
\begin{lstlisting}
let yhat=7+5 in ((),yhat)
\end{lstlisting}

\subsection{Splitting Stage \bbone\ Terms}
\label{sec:split-one}

%Like stage \bbtwo\ splitting, splitting a stage~\bbone\ term $\colone e A$ produces a term $c$ containing all stage~\bbone\ subcomputations in $e$ and a resumer function %$l.r$ containing all stage~\bbtwo\ subcomputations.  
%which respectively contain all the stage \bbone\ and stage \bbtwo\
%subcomputations of $e$. 
%But where the stage \bbtwo\ splitting goal was phrased terms ensure.

%The situation is more complex than when splitting stage
%\bbtwo\ terms; to see why, consider the correctness criterion for splitting
%stage \bbone\ terms.

%Stage \bbone\ evaluation of $e$, via $e\mathbin{\redonesym}[\xi;v]$,
%yields a table of (stage \bbtwo) residuals $\xi$, and a (stage \bbone) partial
%value $v$. 

% Ergo, if we intend to compare the results of evaluation to the those of splitting, 
% then we'll need some mechanism to project from the residual table and partial value only the parts that are relevant at a particular stage.

% But the whole point of splitting is that its results (and their evaluated forms) are monostage.

% Intuitively for splitting TO MATCH THIS THING ABOVE.  It needs to match the 3, and the resumer should reduce to the same value as the reified partial value.


% For functions $\lam xAe$, masking again splits its body $e\splitonesym [c,l.r]$,
% replaces it with the resumer, and uncurries, to yield $\lambda (x,l).r$.


%The only exception is for
%functions $\lam xAe$; such a value represents a computation, so masking splits
%its body as a computation, $e\splitonesym [c,l.r]$, and replaces it with its
%stage \bbone\ component, the combined result.

%They operate by replacing all stage \bbone\
%(resp., \bbtwo) components of a partial value by \texttt{()}. 

%It is tempting to compare the two results of evaluating $e$ to the
%two results of splitting it.

%To see where this goes wrong, consider the stage
%\bbone\ term
%\begin{lstlisting}
%1`(1+2, next{`2`hold{`1`3+4`2`} + 5`1`})`
%\end{lstlisting}
%which evaluates to
%\begin{lstlisting}
%2`[yhat|->7+5]` 1`(3,next{`2`yhat`1`})`
%\end{lstlisting}
%This partial value contains a $\next$, and so is itself multistaged:
%intuitively, its stage \bbone\ part is \texttt{3}, while its stage \bbtwo\ part
%is $\mathtt{\hat{y}}$, which is bound to \texttt{7+5} in the table.

%We formalize this notion via two \emph{masking} functions (\ref{fig:valMask}),
%$\masko{\cdot}$ and $\maskt{\cdot}$, which expose only the relevant structure of
%a partial value at each stage, essentially by replacing all stage \bbone\
%(resp., \bbtwo) components of a partial value by \texttt{()}. 





% % Umut: I made a pass over this, see above.  I don't think I lost
% % anything, so it should be fine to delete this.
% % \section{Splitting Algorithm}
% % \label{sec:splitting}
% % Although terms in \lang\ clearly distinguish their stage~\bbone\ and stage
% % \bbtwo\ components, these components may be interleaved in \lang\ code. The
% % goal of \emph{stage splitting} is to statically separate the stage \bbone\ and \bbtwo\ subcomputations
% % of a term $e$ in \lang\ into a pair of
% % terms $e_1$ and $e_2$ in an unstaged language \langmono, where $e_1$ performs all the
% % stage~\bbone\ subcomputations in $e$ and $e_2$ performs all of the stage~\bbtwo\ subcomputations.
% % Informally, splitting must ensure that running $e_2$ on the output of $e_1$ yields the same result 
% % as evaluating $e$ in \lang. (We make this intuition precise in the subsequent subsections.)

% % Since the mechanics of splitting stage~\bbtwo\ terms are conceptually simpler than those for stage \bbone\
% % terms, we begin by describing how to split stage \bbtwo\ terms before proceeding to more complicated cases.

% % \subsection {Splitting Stage \bbtwo\ Terms}

% % Splitting a stage~\bbtwo\ term $\coltwo e A$ generates
% %  a \emph{precomputation} $p$, and a \emph{resumer} function $l.r$. Whereas direct evaluation of $e$ in \lang\ reduces the stage \bbone\ subcomputations
% % of $e$ in place to create a residual, splitting statically isolates these computations into
% % $p$.  The resumer accepts the value produced by the precomputation as input
% % % (bound to the free variable $l$)
% % and executes all stage~\bbtwo\ subcomputations.   
% % Specifically, if $e$ in \lang\ reduces to the final value $v$, 
% % then after splitting the term $\letin l p r$ should reduce to the same value in \langmono.
% % (Thus, the resumer, bound to the value output by $p$, is equivalent to the residual term defined in~\ref{ssec:dynamics})


% % %	\ur{Correctness will have
% % %	  to go beyond this, by saying for example that all stage 1 parts are
% % %	  in p etc.  Note that this correctness allows a trivial split
% % %	   that shoves everything to r, e.g., p = () and r is ``e''
% % %	  (might need to flatten).}


% % Splitting stage~\bbtwo\ terms, as implemented by the judgment $e \splittwosym
% % [p,l.r]$ in \cref{fig:termSplitTwo} is defined recursively on the structure of $e$.
% % In the terminal cases of constants and variables, splitting generates precomputations that are \texttt{()}
% % (these terms do not involve any stage~\bbone\ computations) and resumers that produce the original term's value.
% % For example, the integer constant \texttt{5} splits into the precomputation \texttt{()} and \texttt{l=>5}.

% % For all non-terminal stage~\bbtwo\ terms $e$ in \lang\ (except $\prev$ and $\pause$), splitting descends into $e$, recursively splitting subterms.  
% % The precompuation is formed by combining the resultant $n$ subterm precomputations into a tuple: $p=(p_1,\ldots,p_n)$.
% % The generated resumer has the same structure as $e$, with every subterm replaced by its resumer.
% % Notice that splitting \texttt{case}s and functions causes the precomputation of subterms to be lifted out from
% % underneath stage \bbtwo\ binders.  % TODO: should probably draw a parallel to the same behavior in dynamics

% % The $\prev$ and $\pause$ rules depends on
% % splitting stage \bbone\ terms, and so they are covered later.

% % %For example, the stage \bbtwo\ term
% % %\begin{lstlisting}
% % %2`hold{`1` 1+2 `2`} < (hold{`1` 3+4 `2`} - 5)`
% % %\end{lstlisting}
% % %has two subterms, the latter of which itself has two subterms. Two are $\pause$s
% % %containing stage \bbone\ computations, while the third has no stage \bbone\
% % %content. 
% % %
% % %\ur{The discussion of the subterms is not helpful. what is the point?}
% % %
% % %The precomputation \emph{lifts} these computations in the same tree
% % %structure: \verb|(1+2,(3+4,()))|.%
% % %\ur{Not clear what a ``tree structure'' is. }
% % %\footnote{In later examples, we will optimize out unnecessary \texttt{()}s.}
% % %The resumer is a function which computes the stage \bbtwo\ value of the original
% % %term by mapping the results of the precomputation in place of the $\pause$s:
% % %\verb|(L1,(L2,_)) => L1 < (L2 - 5)|. 
% % %
% % %\nr{Synopsis of Umut's comments: consider moving some of the easier rules descriptions earlier.}
% % %
% % %Non-staging constructs with $n$ subterms have precomputations which are
% % %$n$-tuples of their subterms' precomputations, and resumers which pass each
% % %component to the resumer of the respective subterm.  

% % \subsection{Splitting Stage \bbone\ Terms}

% % The goal of stage 2 splitting was to generate a precomputation and resumer such that the resumer and the \lang\ residual reduce to the same final value. However, stage~\bbone\ terms do not reduce to final values, rather they reduce to residual tables and partial values.  For example, consider the stage 1 term: 
% % \begin{lstlisting}
% % 1`(1+2, next{`2`hold{`1`3+4`2`} + 5`1`})`
% % \end{lstlisting}
% % which evaluates (via $\mathbin{\redonesym}$), to the following residual table and a multi-stage tuple:

% % \begin{lstlisting}
% % 2`[yhat|->7+5]` 1`(3,next{`2`yhat`1`})`
% % \end{lstlisting}


% % %Like stage \bbtwo\ splitting, splitting a stage~\bbone\ term $\colone e A$ produces a term $c$ containing all stage~\bbone\ subcomputations in $e$ and a resumer function %$l.r$ containing all stage~\bbtwo\ subcomputations.  
% % %which respectively contain all the stage \bbone\ and stage \bbtwo\
% % %subcomputations of $e$. 
% % %But where the stage \bbtwo\ splitting goal was phrased terms ensure.

% % %The situation is more complex than when splitting stage
% % %\bbtwo\ terms; to see why, consider the correctness criterion for splitting
% % %stage \bbone\ terms.

% % %Stage \bbone\ evaluation of $e$, via $e\mathbin{\redonesym}[\xi;v]$,
% % %yields a table of (stage \bbtwo) residuals $\xi$, and a (stage \bbone) partial
% % %value $v$. 

% % Note that this result simultaneously represents information at {\em both} stages: 
% % a stage~\bbone\ value 3, and the stage~\bbtwo\ computation $\letin \yhat {\mathtt{7+5}} \yhat$. 
% % Therefore, to make the results of splitting match the the partial value above, we choose to split \bbone\ terms in \lang\ into a resumer that reduces to the same value as the stage~\bbtwo\ computation, and an $e1$ that not only performs the precomputation expected by the resumer, but also computes values that match the stage~\bbone\ aspects of the partial value.

% % % Ergo, if we intend to compare the results of evaluation to the those of splitting, 
% % % then we'll need some mechanism to project from the residual table and partial value only the parts that are relevant at a particular stage.

% % % But the whole point of splitting is that its results (and their evaluated forms) are monostage.

% % % Intuitively for splitting TO MATCH THIS THING ABOVE.  It needs to match the 3, and the resumer should reduce to the same value as the reified partial value.

% % \subsubsection{Partial Value Masking}

% % To concretize the meaning of ``match", we introduce two {\em partial value masking} functions, $\masko{\cdot}$ and $\maskt{\cdot}$, that project from the residual table and partial value only the subterms that are relevant at a particular stage.  The masking functions are defined in \ref{fig:valMask}. 

% % Since \texttt{next}'s only contain references to the residual table (computations that occur in stage~\bbtwo),
% % the primary operation of $\masko{\xi;v}$ is to replace all $\next$s in $v$ with \texttt{()}.   The result is a \langmono\ value with the same structure as $v$, but containing only its stage~\bbone\ information. Masking is more complex when $v$ is a function since the function's body itself may contain stage~\bbtwo\ subterms.  As a result, masking of functions depends on the general behavior of stage~\bbone\ splitting, described shortly.


% % While $\masko{\cdot}$ produces a value in \langmono,
% % $\maskt{\xi;v}$ produces a \emph{term} in \langmono\ that corresponds to the stage~\bbtwo\ computation represented by $[\xi;v]$.
% % Stage~\bbone\ information in $v$ is discarded by replacing base constants with \texttt{()}, replacing $\next~\hat{y}$ with $\hat{y}$, and eliminating all injection tags. (The sum type is at stage \bbone, so the tag is not relevant at stage \bbtwo.)
% % Last, $\maskt{\cdot}$ reifies $\xi$ around the modified $v$ to produce a term in \langmono. 
% % As with $\masko{\cdot}$, function masking by $\maskt{\cdot}$ depends on general term splitting.

% % % For functions $\lam xAe$, masking again splits its body $e\splitonesym [c,l.r]$,
% % % replaces it with the resumer, and uncurries, to yield $\lambda (x,l).r$.


% % %The only exception is for
% % %functions $\lam xAe$; such a value represents a computation, so masking splits
% % %its body as a computation, $e\splitonesym [c,l.r]$, and replaces it with its
% % %stage \bbone\ component, the combined result.

% % %They operate by replacing all stage \bbone\
% % %(resp., \bbtwo) components of a partial value by \texttt{()}. 

% % %It is tempting to compare the two results of evaluating $e$ to the
% % %two results of splitting it.

% % %To see where this goes wrong, consider the stage
% % %\bbone\ term
% % %\begin{lstlisting}
% % %1`(1+2, next{`2`hold{`1`3+4`2`} + 5`1`})`
% % %\end{lstlisting}
% % %which evaluates to
% % %\begin{lstlisting}
% % %2`[yhat|->7+5]` 1`(3,next{`2`yhat`1`})`
% % %\end{lstlisting}
% % %This partial value contains a $\next$, and so is itself multistaged:
% % %intuitively, its stage \bbone\ part is \texttt{3}, while its stage \bbtwo\ part
% % %is $\mathtt{\hat{y}}$, which is bound to \texttt{7+5} in the table.

% % %We formalize this notion via two \emph{masking} functions (\ref{fig:valMask}),
% % %$\masko{\cdot}$ and $\maskt{\cdot}$, which expose only the relevant structure of
% % %a partial value at each stage, essentially by replacing all stage \bbone\
% % %(resp., \bbtwo) components of a partial value by \texttt{()}. 


Splitting a stage \bbone\ term in \lang\
% $\colone e A$ 
(where $e\mathbin{\redonesym}[\xi;v]$), yields a term 
$e_1$ that performs all stage~\bbone\ subcomputations in $e$ and a \emph{resumer} function $e_2 = l.r$ that performs all stage~\bbtwo\ subcomputations.
For splitting to match the results of evaluating $e$ in \lang,
we require that $e_1$ reduce to the tuple $(y,z)$,
where $y$ is identical to $\masko{\xi;v}$, and 
$\letin l z r$ reduces to the same value as $\maskt{\xi;v}$. Intuitively, $e_1$ performs both the stage~\bbone\ subcomputations needed to produce an \emph{immediate result} $y$, and the stage~\bbone\ subcomputations (called \emph{precomputations}) required to produce the input required by the resumer.

The splitting algorithm for stage~\bbone\ terms, as specified by the
judgment $e \splitonesym [e_1,l.r]$ in \cref{fig:termSplitOne}, proceeds
recursively on the structure of~$e$.  



\TODO REDO THE REST OF THE TEXT TO WALK THROUGH THE MAJOR RULES OF SPLITTING

In general, the 

The rule for $\next$ simply tuples up the precomputation of its subterm with a trivial immediate result,
while the rule for $\prev$ projects the combined result of its subterm to isolate the precomputation.
Since the argument to $\prev$ must have a $\fut$ type, its immediate result must reduce to \texttt{()},
justifying why that part can be thrown away.
The $\pause$ rule treats the entire combined result of its subexpression as a precomputation, 
and projects out the integer result in the resumer.% 
\footnote{The resumer of an integer expression is usually trivial, 
but we have to include it here for termination purposes.}

At stage \bbone\ {\tt case}s, the splitting rules adds injections to the precomputations of each branch. 
This is then cased in the resumer to resume the stage \bbtwo\ portion of the correct branch.
This rule and $\pause$ are the only two places where nontrivial information is added to the precomputation.

The goal of stage 2 splitting was to generate a precomputation and resumer such
that the resumer and the \lang\ residual reduce to the same final value.
However, stage~\bbone\ terms do not reduce to final values, rather they reduce
to residual tables and partial values.  
Therefore, to make the results of splitting match the
the partial value above, we choose to split \bbone\ terms in \lang\ into a
resumer that reduces to the same value as the stage~\bbtwo\ computation, and an
$e_1$ that not only performs the precomputation expected by the resumer, but
also computes values that match the stage~\bbone\ aspects of the partial value.


\subsection{Splitting Stage \bbtwo\ Terms}

Splitting a stage~\bbtwo\ term $\coltwo e A$ generates a
\emph{precomputation}~$p$, and a~\emph{resumer} function $l.r$.  The
resumer accepts the value produced by the precomputation as input
($l$) and performs the stage~\bbtwo\ subcomputations of~$e$.
Specifically, if~$e$ in~\lang\ reduces to the value~$v$, then after
splitting the term $\letin l p r$ also reduces to~$v$ in \langmono.

\ur{I don't quite understand the following.}
(Thus, the resumer, bound to the value output by $p$, is equivalent to
the residual term defined in~\ref{ssec:dynamics})


%	\ur{Correctness will have
%	  to go beyond this, by saying for example that all stage 1 parts are
%	  in p etc.  Note that this correctness allows a trivial split
%	   that shoves everything to r, e.g., p = () and r is ``e''
%	  (might need to flatten).}


The splitting algorithm for stage~\bbtwo\ terms, as specified by the
judgment $e \splittwosym [p,l.r]$ in \cref{fig:termSplitTwo}, proceeds
recursively on the structure of~$e$.  In the terminal cases of
constants and variables, splitting generates precomputations that are
\texttt{()}, because these terms do not involve any stage~\bbone\
computations, and resumers that produce the original term. For
example, the integer constant \texttt{5} splits into the
precomputation \texttt{()} and \texttt{l=>5}.

For all non-terminal stage~\bbtwo\ terms~$e$ in \lang\ (except $\prev$
and $\pause$), splitting descends into~$e$, recursively splitting
subterms and generating precomputations $p_1, \ldots, p_n$ and
resumers $r_1, \ldots, r_n$ for a term with~$n$ immediate subterms.
The precompuation of~$e$ is defined as the combined precomputations:
$p=(p_1,\ldots,p_n)$.  The resumer binds each precomputation to an
argument $(l_1,\ldots,l_n)$ in a term that has the same structure
of~$e$ but where each subterm is replaced by its resumer ($r_i$'s).
Notice that splitting \texttt{case}s and functions causes the
precomputation of subterms to be lifted out from underneath stage
\bbtwo\
binders.  % TODO: should probably draw a parallel to the same behavior in dynamics
\ur{This last point seems important.  It would be important to come
  back to it.}

The $\prev$ and $\pause$ rules depends on
splitting stage \bbone\ terms, and so they are covered later.


%For example, the stage \bbtwo\ term
%\begin{lstlisting}
%2`hold{`1` 1+2 `2`} < (hold{`1` 3+4 `2`} - 5)`
%\end{lstlisting}
%has two subterms, the latter of which itself has two subterms. Two are $\pause$s
%containing stage \bbone\ computations, while the third has no stage \bbone\
%content. 
%
%\ur{The discussion of the subterms is not helpful. what is the point?}
%
%The precomputation \emph{lifts} these computations in the same tree
%structure: \verb|(1+2,(3+4,()))|.%
%\ur{Not clear what a ``tree structure'' is. }
%\footnote{In later examples, we will optimize out unnecessary \texttt{()}s.}
%The resumer is a function which computes the stage \bbtwo\ value of the original
%term by mapping the results of the precomputation in place of the $\pause$s:
%\verb|(L1,(L2,_)) => L1 < (L2 - 5)|. 
%
%\nr{Synopsis of Umut's comments: consider moving some of the easier rules descriptions earlier.}
%
%Non-staging constructs with $n$ subterms have precomputations which are
%$n$-tuples of their subterms' precomputations, and resumers which pass each
%component to the resumer of the respective subterm.  

\input{figures/splitting-term}

\subsection{Optimizations}

The above splitting rules are correct, but can be optimized in many cases. One
major optimization is to eliminate redundant instances of \texttt{()}---for
example, if multiple subterms have a \texttt{()} precomputation, these can be
combined.

A similar issue can occur in the precomputations for recursive function bodies.
Consider the stage \bbtwo\ term
\begin{lstlisting}
2`prev{
  1`letfun fact (n : int) : int = 
    if n <= 0 then 1 else fact(n-1)*n
  in next{`2`hold {`1`fact 5`2`}-100`1`}`2`
}`
\end{lstlisting}
which splits into:
\begin{lstlisting}
1`letfun fact (n : int) : int * prec = 
  if n <= 0 then (1,L) 
  else let (y,z) = fact(n-1) in (y*n,R z)
in fact 5`

2`l => 
letfun fact (n : unit, l0 : prec) : unit = 
  case l0 of L => () | R l1 => fact ((),l0)
in (fact (pi2 l); pi1 l)-100`
\end{lstlisting}
\texttt{fact}, being a stage \bbone\ function, itself splits into two recursive
functions, which compute a combined result (stage \bbone\ result and
precomputation), and a stage \bbtwo\ result, respectively. This precomputation
could be given the type
\begin{lstlisting}
datatype prec = L | R of prec
\end{lstlisting}
while the stage \bbtwo\ result is always \texttt{()}.

It is wasteful to run the stage \bbtwo\ version of \texttt{fact}, since it
always returns \texttt{()}; worse yet, it has linear runtime!

We solve this issue by adding a new staging annotation to \lang, called
\texttt{mono}. $\monoSt~e$ is stage \bbone, and requires that $e$ contains
no stage \bbtwo\ subexpressions. This adds a new stage \bbmono\ and two new
rules to \lang:
\begin{mathpar}
\infer{\typesone{\monoSt~e}A}{\typesmono e A} \and
\infer{\diaone{\monoSt~e}{\cdot;v}}{\diaone{e}{\cdot;v}}
\end{mathpar}

\crem{Why is it difficult?}

To split \texttt{mono} terms, we must produce a resumer with the correct shape
for the enclosed term. This is difficult to produce statically, because the
language has sums and general recursion. We instead produce it dynamically,
using a new value in \langmono, \texttt{dummy}, which can be consumed as though
it had any type:
\begin{mathpar}
\infer{e_1~e_2~\redsym~\mathtt{dummy}}{e_1~\redsym~\mathtt{dummy} & e_2~\redsym~v} \and
\infer{\unroll~e~\redsym~\mathtt{dummy}}{e~\redsym~\mathtt{dummy}}\and
\infer{\pio~e~\redsym~\mathtt{dummy}}{e~\redsym~\mathtt{dummy}}\and
\infer{\pit~e~\redsym~\mathtt{dummy}}{e~\redsym~\mathtt{dummy}}
\end{mathpar}

\crem{Explain $\overset{C}{\to}$.}

The splitting rules are then
\begin{mathpar}
\infer{\splitone{\monoSt~e}A {e', {\tt dummy}} }{e \overset{C}{\rightarrow} e'} \and
\infer{e_1~e_2 \overset{C}{\rightarrow} \pio~(e_1'~e_2')}{e_1 \overset{C}{\rightarrow} e_1' & e_2 \overset{C}{\rightarrow} e_2'} \and
\infer{\lambda x.e \overset{C}{\rightarrow} \lambda x.(e',())}{e \overset{C}{\rightarrow} e'}
\end{mathpar}
And $\overset{C}{\rightarrow}$ operates like a map at all other terms.

To see that this optimization is correct, notice that \texttt{dummy} can only
appear in the resumers of terms that have no circles in their \lang\ type.
Since the $\prev$ rule requires a circle type, dummy values cannot leak from the
resumers of stage \bbone\ terms into the resumers of stage \bbtwo\ terms.

\input{figures/splitting-misc}

\subsection{Implementation}

\crem{Say something about the implementation.}

