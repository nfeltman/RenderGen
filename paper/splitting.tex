%!TEX root = paper.tex

\section{Splitting Algorithm}
\label{sec:splitting}

%\input{figures/splitting-overview}

\begin{abstrsyn}

Splitting statically transforms terms in \lang\ into a pair of
monostaged terms ($f_1$ and $f_2(-)$) that correspond to the first
stage and second stage computations in the original term. Since full
evaluation of world \bbtwo\ terms (both first stage and second stage
evaluation) only produces values in stage two, the idea of splitting
is to generate terms where evaluating $f_1$ in a first pass, and then
evaluating $f_2$ on the result of the first pass, yields the same
value as full evaluation of the original \lang\ program.

Similarly, when splitting \bbonem\ terms, first pass evaluation of
$f_1$ should produce the same value as first stage evaluation of the
original \lang\ term.  However, complexity arises because
\bbonem\ terms may also contain computations to be evaluated in the
second stage. (For example, a \bbonem\ term of type $\fut \rmint$
results in an \rmint\ value in the second stage.) Thus we also want
the second pass evaluation of $f_2$ on the outputs of $f_1$ to yield
the same value as fully evaluating all second stage computations in
the original \bbonem\ term. Finally, when splitting \bbonep\ terms,
which only produce values in the first stage, we only need to compare
the result of $f_1$ with that of the \lang\ term.

Handling the asymmetry between the results of evaluating
\bbonem\ terms (which may produce results at both the first and second
stage) and \bbtwo\ terms (which only produce second stage results) is
fundamental to the structure of the splitting algorithm presented in
this section.

\textbf{\bbtwo\ term splitting.}  For any $\coltwo e A$ which reduces
to a residual $q$ (via $\diatwo e q$) and then a final value $v$ (via
$\reduce q v$), splitting $e$ (via the new relation~$\splittwosym$)
yields a pair of monostaged terms $\pipeS p l r$. ($p$ and $l.r$
contain all first and second stage computations in $e$ respectively.)
Executing $p$ in a first pass produces $b$ (via $\reduce p b$). Then,
in the second pass, $\reduce {[b/l]r} {v'}$, where $v'$ is the same as
$v$.  Since execution of the first pass serves to generate input for
the second pass, we say $p$ is a {\em precomputation} that produces a
{\em boundary value} ($b$) for the {\em resumer} ($l.r$).

% The process of splitting \bbtwo\ terms is given by via the new
% relation~$\splittwosym$.

%masking yields the masked value $\mval i q$ (via~$\vsplito$)

\textbf{\bbonem\ term splitting.}  For any $\colmix e A$ which reduces
to $\rtab \xi v$ (via $\redonesym$) , splitting $e$ (via the new
relation~$\splitonesym$) again yields the pair of monostage terms
$\pipeM c l r$. Evaluating $c$ in the first pass produces the pair
$(i,b)$, where the first element $i$ matches the first stage results
contained in $v$.  For example, in the simple case where $\rtab \xi v$
contains entirely first stage computation, such as:
\begin{lstlisting}
2`[]`1` grnd{1+2}`
\end{lstlisting}
the first stage result is the value 3.  The second element of the pair
is the boundary value used as input to the resumer in second pass
evaluation as $\reduce {[b/l]r} {v'}$, where $v'$ is the same as
result produced by second stage computations in $e$.  For example, in
the case where $\rtab \xi v$ contains entirely second stage
computation, such as:
\begin{lstlisting}
2`[yhat |-> 2+3]`1` next{`2`yhat`1`}`
\end{lstlisting}
the second stage result is the value 5. Since in general residual
tables and partial values describe a mixture of both first and second
stage computations, in the subsequent subsection we define an
operation, called {\em masking}, that separates residual tables and
partial values into their first and second stage results. We then
describe the algorithm for splitting both \bbonem\ terms
($\splitonesym$) and \bbtwo\ terms ($\splittwosym$).


%Since $c$ ensapulates computations that produce both $e$'s first-stage
%result and also the boundary value required by the resumer, we refer
%to it as a {\em combined term}.

%Note that since $\coltwo e A$ reduces to an entirely second-stage
%residual, its first-stage computations only exist to generate input
%for second stage computations.  In contrast, since $\colmix e A$
%reduces to a multi-stage residual table and partial value, its first
%stage computations serve to both generate the value used as input for
%the second stage {\em and also} produce a first-stage value.
%Correspondingly, the precomputation $p$ resulting from splitting
%\bbtwo\ terms reduces only to a boundary value $b$ which is passed to
%the resumer; but the combined term $c$ resulting from splitting
%\bbonem\ terms reduces to a tuple containing both the first stage {\em
%  immediate result} $i$ and the boundary value $b$ (motivating the
%name {\em combined term}). 

\subsection{Masking}
\label{sec:masking}

%Masking separates residual tables and partial values into first stage
%results and second stage residuals.

Masking (given by the relation $\vsplito$) converts a residual table $\xi$
and associated partial value $v$ into a masked value $\mval i q$.
%that explicitly separates the first stage components of 
%result from the residual.
%where $i$ is a monostage value encoding all
%first stage components of the partial value, and $q$ is a monostage
%term encoding all of the second-stage computations of the partial
%value.
The first part of the masked value, $i$, is a monostage value holding
the result of all first stage components of $v$.  The second
component, $q$, is a residual representing all second stage
computations in $\xi$ and $v$.

%(A precise definition of masking is
%given in \ref{sec:masking}.)

%Masking is not a transformation performed as part of the splitting
%algorithm.  Instead, masking defines an intuitive notion of the first
%stage and second stage ``components'' of residual tables and partial
%values, and it is used to define the requirements of what output
%splitting of \bbonem\ terms must produce.
To provide intuition about the intent of masking, consider the
following residual table and partial value:
\begin{lstlisting}
2`[yhat |-> 1+2]`1` (next{`2`yhat`1`}, injL (grnd{7}, next{`2`yhat`1`}))`
\end{lstlisting}
To construct the value $i$ representing its first-stage components,
masking first redacts all second stage (blue) parts, along with the
surrounding \texttt{next} annotations. (This redaction removes the
entire residual table since it only represents second stage
computations.) The resulting ``holes'' in the term are replaced with
unit values.
%\begin{lstlisting}
%4`##########`1` (`4`######`1`, injL (grnd{7}, `4`######`1`))`
%\end{lstlisting}
%The holes inside the term needs to be filled with something to convey the lack of information, so we use a unit values:
\begin{lstlisting}
1`((), injL (grnd{7},()))`
\end{lstlisting}
Finally, masking drops \texttt{grnd} annotations yielding:
\begin{lstlisting}
1`((), injL (7,()))`
\end{lstlisting}
To construct the residual $q$ (corresponding to second stage computations) masking first redacts all \texttt{grnd} blocks
(replacing them with unit), \texttt{next} annotations, and injection tags:
%\begin{lstlisting}
%2`[yhat |-> 1+2]`1` (`4`####`2`yhat`4`#`1`, `4`####`1` (`4`####`1`,`4`####`2`yhat`4`#`1`))`
%\end{lstlisting}
%Where the \texttt{grnd} blocks left a hole, we put in a unit values:
\begin{lstlisting}
2`[yhat |-> 1+2] (yhat, ((),yhat))`
\end{lstlisting}
Then the residual table is reified into \texttt{let} bindings,
yielding:
\begin{lstlisting}
2`let yhat = 1+2 in (yhat, ((),yhat))`
\end{lstlisting}
A precise definition of the masking relation is given in
\ref{fig:valMask}.

%Since lambdas may represent multi-stage computations, masking splits
%the body of lambdas as general world \bbonem\ terms (as described in
%\ref{sec:split-one}), and packages the resulting terms as functions in
%both the first and second stage parts of the masked value.

% Masking operates by first inducting on the entries of the residual table.  
% Being purely second-stage content, these are reified into let statements at the top of the resumer.
% Once the table is empty, masking inducts on value itself.

% Masking assigns ground values to the immediate value
% and likewise assigns references into the residual table to the resumer.
% In both cases, the alternate component is assigned to $\tup{}$, to represent trivial information.
% Note that the \texttt{grnd} and \texttt{next} annotations are erased.

% Masking distributes into tuples, injections, and rolls, since their subvalues may have content at both stages.
% However, the tags of injections and rolls are replicated only in the immediate value, 
% since they represent first-stage information.

\subsection{Term Splitting at \bbonem}
\label{sec:split-one}

Given the definition of masking, we now describe how to split
\bbonem\ terms. The algorithm, given in \cref{fig:termSplit}, proceeds
recursively on the structure of~$e$. We derive a few cases here.

\paragraph {Unit.} 
As a simple first case, consider splitting the unit value, $\tup{}$
which masks to $\mval {\tup{}} {\tup{}}$.
%Units trivial contain unit split into more units: $\tup{} \vsplito \mval {\tup{}} {\tup{}}$.
Splitting must produce a $c$ and $l.r$ satisfying,
\[
	\reduce c {\tup{\tup{},b}} \text{ and } [b/l]r \equiv \tup{}
\]
Our algorithm uses $c=\tup{\tup{},\tup{}}$ and $l.r = \_.\tup{}$.
Splitting $\pure{e}$ follows in similar fashion, except the immediate
result now becomes the result of evaluating the \bbonep\ term $e$.

\paragraph {Injections.}
Now consider splitting the non-terminal, $\inl {e}$, where $\diaone
{e} \xi v$ and $\rtab \xi v \vsplito \mval i q$. Therefore:
\[
	\splitone e A c {l.r} \text{ and } \reduce c {\tup{i,b}} \text{ and } [b/l]r \equiv q
\]
Since $\diaone {\inl e} \xi {\inl v}$ and $\rtab \xi {\inl v} \vsplito \mval {\inl i} q$,
splitting must produce a $c'$ and $l.r'$ satisfying,
\[
	\reduce {c'} {\tup{\inl i,b'}} \text{ and } [b'/l]r' \equiv q
\]
Our algorithm generates a first-pass term $c'$ that produces the same
boundary value ($b$) as the split of the subexpression $e$:
\[
c' = \letin {\tup {x,y}} c {\tup{\inl x, y}}
\]
Splitting also generates the same resumer as the split of the
subexpression ($l.r' = l.r$)

\paragraph{Tuple.} For an example of splitting terms with more than one argument, consider the tuple $\tup{e_1,e_2}$,
where $\diaone {e_k} {\xi_k} {v_k}$ and $\rtab {\xi_k} {v_k} \vsplito
\mval {i_k} {q_k}$ for $k = 1,2$.  Inductively:
\[
	\splitone {e_k} A {c_k} {l_k.r_k} \text{ and } \reduce {c_k} {\tup{i_k,b_k}} \text{ and } [b_k/l_k]r_k \equiv q_k
\]
Since $\diaone {\tup{e_i,e_2}} {\xi_1,\xi_2} {\tup{v_1,v_2}}$ 
and $\rtab {\xi_1,\xi_2} {\tup{v_1,v_2}} \vsplito \mval {\tup{i_1,i_2}} {\tup{q_1,q_2}}$,
the validity of the split $\splitone {\tup{e_1,e_2}} A {c} {l.r}$ requires,
\[
	\reduce {c} {\tup{\tup{i_1,i_2},b}} \text{ and } [b/l]r \equiv \tup{q_1,q_2}
\]
To satisfy this, our algorithm uses a boundary value which is the tuple of the boundary values of the subexpressions,
$b = \tup{b_1,b_2}$. This is deconstructed with a tuple pattern, $l.r = \tup{l_1,l_2}.\tup{r_1,r_2}$,
and constructed using,
\[
c = \letin{\tup{y_1,z_1}}{c_1}{\letin{\tup{y_2,z_2}}{c_2}{\tup{\tup{y_1, y_2},\tup{z_1, z_2}}}}
\]

\paragraph {Case}
Splitting is most complicated at $\caseof {e_1} {x_2.e_2} {x_3.e_3}$ terms because of their divergent control flow.
Consider that when $\reduce {e_1} {\inl {v_1}}$, both the first and second stage component of $e_2$ will be executed, 
but $e_3$ will be ignored entirely. The reverse occurs when $\reduce {e_1} {\inr {v_1}}$.
This implies that both the first and second stage results of splitting will need to have \texttt{case} statements.

Recovering first stage divergence is easy, since for $\splitone {e_1} ? {c_1} {l_1.r_1}$, 
$\reduce {e_1} {\inl {v_1}}$ implies $\reduce {c_1} {\tup{\inl {i_1},b_1}}$.
Thus the algorithm cases on $c_1$ to run the correct branch of first stage code.
The boundary value from this correct branch, $b_2$ or $b_3$, is packaged as either $\tup {b_1, \inl {b_2}}$ or $\tup {b_1, \inr {b_3}}$.

The resumer for \texttt{case} operates by untupling the boundary value to get $b_1$ and either $\inl {b_2}$ or $\inr {b_3}$.
The resumer of the predicate is run using $b_1$, and the remaining injection is inspected to run the correct branch resumer.

\paragraph {Function} 
Function introduction has a $\tup{}$ boundary value,
since functions are already fully reduced in our semantics.
However, since the body of a function may itself be multistage, splitting must continue into it.
The immediate result is a new function formed from the first-stage part of the original body.
The resumer is a new function formed out of the second-stage part of the original body.
It is the responsibility of the application site to save the precomputation of the function body
and pass it to the resumer version of the function.

\subsection{Term Splitting at \bbtwo}

Because world \bbtwo\ terms in \lang\ reduce to monostage residuals (as opposed to partial values),
term splitting at world \bbtwo\ is simpler and more uniform than the version at \bbonem. 
The algorithm is specified by the $\splittwosym$ relation in \cref{fig:termSplit}.

Consider any (except \texttt{prev}) 
$n$-ary term $e = \scriptCapp {e_1 \ttsemi \ldots \ttsemi e_n}$.
First note that for any $\diatwo e q$, $q$ must have the form $\scriptCapp {q_1 \ttsemi \ldots \ttsemi q_n}$,
even under binders and for nullary terms.
For each $k \in \{1,\ldots,n\}$, the invariant for stage \bbtwo\ splitting of $e_k$ is,
\[
	\splittwo {e_k} A {p_k} {l_k} {r_k} \text{ and } \reduce {p_k} {b_k} \text{ and } [{b_k}/{l_k}]{r_k} \equiv {q_k}
\]
To match the invariant for a split $\splittwo {\scriptCapp {e_1 \ttsemi \ldots \ttsemi e_n}} A p l r$, we require,
\[
	\reduce p b \text{ and } [b/l]r \equiv \scriptCapp {q_1 \ttsemi \ldots \ttsemi q_n}
\]
Our algorithm accomplishes this by using $p = \tup {p_1, \ldots, p_n}$ and
$l.r = \tup {l_1, \ldots, l_n}.\scriptCapp {r_1 \ttsemi \ldots \ttsemi r_n}$.
Again, this works even for nullary terms and under binders.

Splitting \texttt{prev} generates a precomputation that projects the immediate
result of its world \bbone\ subterm.
Since the argument to \texttt{prev} is of $\fut$ type, its immediate result reduces to $\tup{}$, justifying why it can be thrown away.
Finally, splitting \texttt{next} simply tuples up the precomputation of its
world \bbtwo\ subterm with a trivial immediate result $\tup{}$.

\subsection {Role of World \bbonep}
\label{sec:needGround}

The splitting algorithm described in the previous subsections operates
purely on the local structure of \lang\ terms.  One artifact of this design
is that splitting \bbonem\ terms may generate resumers containing
unnecessary logic.  For example, the rule for splitting
\bbonem\ \texttt{case} terms inserts the tag from the \texttt{case}
argument into the boundary value, then decodes this tag in the
resumer. This logic occurs regardless of whether the terms forming the
branches of the \texttt{case} contain second stage computations.
Worse, if this \texttt{case} appeared in the body of a recursive
function with no other second stage computations, splitting would
generate a resumer with (useless) recursive calls.

Rather than attempt global optimization of the outputs of splitting,
we instead leverage the type system to indicate when a term contains
no second-stage computations by adding a third world \bbonep\ whose
terms are purely first stage.  While not necessary for ordinary staged
term evaluation (\ref{sec:stagedsemantics}), this annotation is
particularly useful for splitting. Specifically, splitting $\pure e$
terms trivially yields a unit resumer.

The \texttt{partition} function in the \texttt{quickselect} example in
\ref{sec:exampleQS} is an example of such a function that contains no
second stage computations, but, if not defined within a $\pure$
annotation, would cause splitting to generate a recursive resumer.

\end{abstrsyn}

\input{figures/splitting-misc}
\input{figures/splitting-term}
