%!TEX root = paper.tex

\section{Overview}
\label{sec:overview}

\begin{abstrsyn}

\input{figures/quickselect}

Suppose that we wish to perform a series of order statistics queries
on a list \texttt{l}. To this end, we can use the quickselect
algorithm~\cite{Hoare:1961}, which given a list \texttt{l} and a rank
\texttt{k}, returns the element of \texttt{l} with rank \texttt{k}.
As implemented in an ML-like language in \ref{fig:qs-unstaged},
\texttt{qs} partitions \texttt{l} using the first element as
a pivot, and then recurs on one of the two resulting sides, depending on
the relationship of \texttt{k} to the size \texttt{i} of the first half, in
order to find the desired element.  Assuming that the input is uniformly
randomly ordered (which can be achieved by prepermuting the input), \texttt{qs}
runs in expected $O(n)$ time.
%
Using \texttt{qs}, we can perform $m$ different order statistics queries with
ranks $\mathtt{k1},\dots,\mathtt{km}$ as follows:
%
\begin{lstlisting}
(qs l k1, qs l k2, ..., qs l km)
\end{lstlisting}
%
Unfortunately, this approach requires $O(n \cdot m)$ time.

We can attempt to improve on this algorithm by factoring out computations shared
between these calls to \texttt{qs}. In particular, the comparisons performed by
\texttt{partition} depend only on \texttt{l}, although different calls to
\texttt{partition} are made by each call to \texttt{qs}.

A first cut at a solution might be to, in a first pass, sort \texttt{l} into
\texttt{s}, and then in a second pass, perform lookups in \texttt{s}.
Unfortunately, lookups in \texttt{s} are also $O(n)$ on average, since since
\texttt{s} is a list, leading to no improvement in efficiency.  

A more sophisticated solution is to, in a first pass, construct a binary search
tree out of \texttt{l}, and in a second pass, simply look for the \texttt{k}th
leftmost element of that tree. To do this efficiently requires one more
innovation---storing at each node the size of its left subtree (i.e., using
\emph{augmented trees}). This approach has (expected) runtime $\Theta(n\log{n} +
m\log{n})$, a nearly linear-time improvement in $m$.

In both cases, we replace our simple solution with a two-pass algorithm which
first processes the input into a lookup data structure, and then subsequently
performs fast lookups. Improving algorithms in this way is highly non-trivial,
as it requires reasoning about intricate algorithmic concerns, and implementing
more complex algorithms and data structures.  

In this paper, we present a splitting algorithm which transforms staged programs
into multi-pass programs. In certain cases, this algorithm \emph{automatically}
improves algorithms in the way described above.

%Such transformations, called pass-separation by J{\o}rring and
%Scherlis are commonly employed.  For example, as briefly mentioned in
%\ref{sec:intro}, modern graphics software is written exactly in this
%way.  Unfortunately, as the example illustrates, multipass programs
%are naturally complex.  

\subsection{Staging}

%The example itself is also implemented in our implementation.

The idea behind staged programming is to use staging annotations---in our case,
guided by types---to indicate the stage of each subterm. We consider a
language \lang\ with two modal worlds representing the two stages, and a third
{\em ground} world of unstaged terms.

In \ref{fig:qs-staged} we show a staged version of \texttt{qs}, called
\texttt{qss}, where first-stage code is colored red, and second-stage blue. In
\texttt{qss}, we regard the input list as arriving in the first stage
(with type $\curr\mathrm{list}$, a list ``now''), the input rank as arriving in
the second stage (with type $\fut\rmint$, an integer in the ``future''), and the
result as being produced in the second stage (with type $\fut\rmint$).

\texttt{qss} is obtained from \texttt{qs} by wrapping certain computations with
\texttt{prev} and \texttt{next}, signaling transitions between first- and
second-stage code, and $\texttt{g}$, signaling ground terms.  
%
We also use a function \texttt{hold},
\lstinline{1`hold : ^int -> $`2`int`},
to promote first-stage integers to second-stage integers.
%
Our type system ensures that the staging annotations in \texttt{qss} are
consistent, in the sense that computations marked as first-stage cannot depend
on ones marked as second-stage.

The process of adding staging annotations to unstaged code has been
the subject of extensive research (\ref{sec:related}). In this paper, we do not
consider this problem, instead assuming that the annotations have been provided.
In the case of \texttt{qss}, we have specifically chosen annotations which
maximize the work performed in the first stage.

\subsection{Splitting Staged Programs}

\input{figures/quickselect-split}

The staged quickselect code shown in \ref{fig:qs-staged} makes
explicit the staging of all terms, making it natural to ask, whether
we can transform this code into manually implemented multi-pass code
described above and match the efficiency improvements of the manual
implementation. Considering the algorithmic knowledge and the
considerations needed, this may seem like a tall order.
Interestingly, our splitting algorithm achieves exactly this.
In the rest of this section, we present a brief, high-level overview
of the main ideas behind this algorithm using the quickselect example.
%

When applied to the staged code in \ref{fig:qs-staged}, our splitting
algorithm yields a two-pass program that uses the binary-search-tree
based implementation.  Specifically, in its first pass, the two-pass
program takes the input list and constructs a probabilistically
balanced binary search tree, which is isomorphic to a treap data
structure~\cite{SeidelAr96}.  In the second pass, the program performs,
for each rank, a binary search tree lookup, by walking the tree to
find the element with the desired rank.
%
\ref{fig:qs-staged} illustrates the code for the first and second
passes \texttt{qs1} and \texttt{qs2} of the staged function
\texttt{qss}.


To create the multi-pass algorithm, the splitting algorithm operates
by composing local transformations on the subterms of the input
program.  In particular, the algorithm has no special knowledge of the
quickselect algorithm, binary search trees, or how to perform lookups
on binary search trees, but it is able to derive them from the input
program.
%

The splitting algorithm scans the program code for first-stage
computations (which depend only on first-stage values) and separates
them into the function, \texttt{qs1} of the first pass. This function
performs the first-stage computations and places the results into a
boundary data structure that both records the control flow and the
results from the first stage at relevant control-flow points.  More
specifically, the function \texttt{qs1} performs all the recursive
calls and evaluates all instances of the partition function, which
depend only on the input list.  The function produces a boundary data
structure that collects the results from all recursive calls along
with a tag that indicates the control branches taken.  Since
\texttt{qss} has a binary control structure (casing on the list), the
boundary is a binary tree.  To ensure that the trace contains the
necessary results to complete the execution in the second pass, where
second-stage values may be used, the splitting algorithm includes in
the nodes of the tree information such as the "pivot" used for
splitting and the size of the subtree at that note.  The resulting
tree is thus not just a tree but a binary search tree, keyed by the
pivot and augmented with "size" information.

As the splitting algorithm scans \texttt{qss} for computations that
can be performed in the first stage, it also collects computations
that must be left to the second stage in a separate function
\texttt{qs2}.  This function, which is executed in the second pass,
takes as argument the boundary and the second-stage argument (the
rank) and performs a lookup in the boundary data structure.  But how
does \texttt{qs2} knows to traverse the tree? It does not. Since
the splitting algorithm recorded the control flow of the first-stage
execution in the boundary data structure, \texttt{qs2} simply follows
this control structure and performs at each point the parts of the
computation from \texttt{qss} that can now be performed in the
presence of the second-stage argument (the rank).  In the context of
our example, this performs a lookup on the boundary data structure by
using the supplied rank.

\begin{theorem}
  Consider an execution of \texttt{qs1} with a randomly permuted input
  of $n$ keys and performing $m$ executions of \texttt{qs2} with the
  result of \texttt{qs1}.  The total run-time for this computation is
  $\Theta(n\log{n} + m\log{n})$ in expectation.
\end{theorem}
\begin{proof}
  We use a few standard facts.  We note first that \texttt{qs1} is
  isomorphic to a quick-sort algorithm but builds a binary search tree
  instead of combining the returned results in a list.  The run-time
  for \texttt{qs1} is thus (expected) $\Theta(n\log{n})$.
%
  The depth of the tree generated by \texttt{qs1} is isomorphic to the
    depth of a run of the quickselect algorithm or equivalently to the
    span of a parallel implementation of the quicksort algorithm, both
    of which are known to be (expected) $\Theta(\log{n})$.
%
    By inspection of \texttt{qs2}, we can see that the algorithm takes
    time proportional to the depth of the binary search tree, which is
    $\Theta(\log{n})$. Consider now a random variable for each of the
    $m$ invocations of \texttt{qs2}, each of which takes expected
    $\Theta(\log{n})$ time.  Since the total time is the sum of these
    random variables and since the expectation of the sum is sum of
    the expectations of the random variables, the bound follows.
\end{proof}

\end{abstrsyn}
