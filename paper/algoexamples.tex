

\section{Examples of Algorithm Derivation}
\label{sec:examples}

We investigate two applications of our splitting algorithm.

In the first application, we split a staged search algorithm where the data comes at stage \bbone\ and the search index comes at stage \bbtwo.  
In the second application, we split a staged interpreter where the source program comes at stage \bbone, and some input to the program comes at stage \bbtwo.
 
We urge the reader to pay attention to how partial evaluation (\lang's dynamic semantics) and stage splitting compare for these examples.
The main difference to note is that where splitting creates an explicit data structure, partial evaluation will
essentially embed that data structure in the residual. 

%\subsection{Fast Exponent}
%
%Here is a staged version of the fast-exponent example from before.
%\begin{lstlisting} 
%fun fexp (b : $int, e : int) : $int =
%	if e == 0 then
%		next{1}
%	else if (e mod 2) == 0 then
%		next{let x = prev{fexp(b,e/2)} in x*x}
%	else
%		next{prev{b} * prev{fexp (b,e-1)}}		
%\end{lstlisting}
%
%\noindent
%{\tt fexp} splits into the following two functions:
%
%\begin{lstlisting} 
%fun fexp1 (b, e) =
%  ((), roll (
%    if e == 0 then inj1 ()
%    else
%      inj2 (
%        if (e mod 2) == 0
%        then inj1 (#2 (fexp1 (b,e/2)))
%        else inj2 (#2 (fexp1 (b,e-1)))
%      )
%  ))
%
%fun fexp2 ((b, e), p) =
%	case unroll p of
%	  inj1 () => 1
%	| inj2 d =>
%		case d of
%		  inj1 r => let x = fexp2 ((b,()),r) in x*x
%		| inj2 r => b * fexp2 ((b,()),r)
%\end{lstlisting}
%
%Although split programs are not typed, we'll recognize the intermediate data structure 
%above as being as isomorphic to the recursive datatype definitions:
%\begin{lstlisting} 
%datatype binaryList = Empty 
%                      | NotEmpty of neList
%withtype neList = Zero of binaryList 
%                  | One of binaryList
%\end{lstlisting}
%Which is all to say that the split code precomputes a binary representation of the exponent.
%Since integers are usually stored in a binary format anyways, this isn't practically useful,
%but it's still an interesting exposition of the technique.
%
%Partially evaluating the code here might actually be useful, since the residual wouldn't have branches,
%and exponents tend to be small enough that the code size would be reasonable.

\subsection{Quickselect}

We have observed that stage splitting can be used to transform \lang\ programs into two step algorithms where the precomputation generates a data-structure, and the residual uses the precomputed structure to accelerate repeated computation.  

The function {\tt qs} in the code below is a staged version of the quickselect algorithm.
Standard quickselect finds the $i$th largest number in a list (l) by recursively partitioning the list by its 
first element and picking the side which contains the $i$th largest element.
In this case, we've staged quickselect by saying that the list is stage \bbone\ and $i$ is stage \bbtwo.
The helper function {\tt partition} operates entirely in stage \bbone, and so we have wrapped it in a \texttt{mono}.

\begin{lstlisting} 
datatype list = Empty | Cons of int * list
/* helper function */
val partition = mono {
  let fun partition ((p,l) : int*list) 
  : (int*list*list) =
    case unroll l of 
      Empty => (0,Empty, Empty) 
    | Cons (h,t) =>
        let (s,left,right) = partition (p,t) in
        if h<p 
        then (s+1,Cons(h,left),right)
        else (s,left,Cons(h,right))
  in partition
}

fun qs (l : list, i: $int) = 
  case l of
    Empty => next {0}
  | Cons (h,t) => 
      let (n,left,right) = partition (h,t) in
      next{
        let n = hold{n} in
          case compare prev{i} n of
            LT => prev {qs left i}
          | EQ => hold {h}
          | GT => prev {qs right next{prev{i}-n-1}}
      }	
\end{lstlisting}

\noindent
Running stage splitting on this code produces:

\begin{lstlisting} 
datatype _ = Empty | Cons of _
fun partition (p,l) =
  case unroll l of 
    Empty => (0,Empty, Empty) 
  | Cons (h,t) =>
      let (s,left,right) = partition (p,t) in
      if h<p 
      then (s+1,Cons(h,left),right)
      else (s,left,Cons(h,right))

fun qs1 (l, i) = roll((), 
  case l of
    Empty => inj1 ()
  | Cons (h,t) => 
      inj2 (
        let (left,right,n) = partition h t in
        (n, #2 (qs1 left i), h, #2 (qs1 right i))
      )
  )

fun qs2 ((l, i), p) = 
  case unroll p of
    inj1 () => 0
  | inj2 (n,p1,h,p2) => 
      case compare prev{i} n of
        LT => qs2 () i
      | EQ => h
      | GT => qs2 () (i-n-1)
\end{lstlisting}

These functions recursively build ({\tt qs\_1} and then search ({\tt qs\_2}) a binary tree,
which stores a set element and subtree size at every branch.
All of the list partitioning work now occurs within the precomputation.

Partial evaluation creates a giant tree of if statements proportional to the size of the list,
whereas splitting just creates the tree out of values, and then interprets it in the residual.
For large input lists (which is typical), this saves a lot on memory.

This works well because quickselect does a lot of work at stage one that can be amortized across all of stage two.

Also, the behavior where we lift precomputations out from branches is very important.

%\subsection{Trie}
%
%Our last example is one which generates a trie intermediate data structure.
%
%The function {\tt exists} below determines whether a query string (s) occurs in a given set of strings (from the alphabet $\{A, B,C\}$).
%It solves this problem by partitioning the provided set of strings into three subsets,
%one which contains all words that start with $A$,
%one which contains all words that start with $B$, and one for $C$.
%When partitioning, we also throw away the first letter, since we know it's uniform for the whole subset.
%Also while doing this partitioning, we also keep track of whether the empty word occurred at all.
%We then look at the query string.  If it's empty, we return whether the empty word was in the set.
%Otherwise, we look at the first letter, pick the appropriate subset, 
%and recursively search for the rest of our query string in that.
%
%We stage this algorithm by saying that the word set comes at stage \bbone\
%and the query string comes at stage \bbtwo.
%
%\begin{lstlisting} 
%datatype letter = A | B | C
%datatype string = EmptyS | ConsS of letter * string
%datatype list = EmptyL | ConsL of string * list
%/* helper function */
%fun partition (l : list) : (bool * list * list * list) =
%  case l of
%    EmptyL => (false,EmptyL,EmptyL,EmptyL)
%  | ConsL (s,ss) =>
%      let (anyEmpty,a,b,c) = partition ss in
%      case unroll s of
%        EmptyS => (true,a,b,c)
%      | ConsS (z,zs) =>
%          case z of 
%            A => (anyEmpty, ConsL(zs,a), b, c) 
%          | B => (anyEmpty, a, ConsL(zs,b), c) 
%          | C => (anyEmpty, a, b, ConsL(zs, c))
%fun exists ((l,s) : list * $string) : $bool =
%  case l of 
%    EmptyL => next{false} 
%  | ConsL _ => 
%    let (anyEmpty, a, b, c) = partition l in
%    next {
%      case prev{s} of
%        EmptyS => prev{
%          if anyEmpty then next{true} else next{false}
%          }
%      | ConsS (z,zs) =>
%          case z of
%            A => prev{exists (a,next{zs})}
%          | B => prev{exists (b,next{zs})} 
%          | C => prev{exists (c,next{zs})}
%    }
%\end{lstlisting}
%
%\noindent
%Running the splitting algorithm on this code produces:
%
%\begin{lstlisting} 
%datatype _ = EmptyS | ConsS of _
%datatype _ = EmptyL | ConsL of _
%fun partition l =
%  case l of
%    EmptyL => (false,EmptyL,EmptyL,EmptyL)
%  | ConsL (s,ss) =>
%      let (anyEmpty,a,b,c) = partition ss in
%      case unroll s of
%        EmptyS => (true,a,b,c)
%      | ConsS (z,zs) =>
%          case z of 
%            A => (anyEmpty, ConsL(zs,a), b, c) 
%          | B => (anyEmpty, a, ConsL(zs,b), c) 
%          | C => (anyEmpty, a, b, ConsL(zs, c))
%fun exists1 (l,s) = roll ((), 
%  case l of 
%    EmptyL => inj1 ()
%  | ConsL _ => 
%    let (anyEmpty, a, b, c) = partition l in
%    inj2 (
%    	if anyEmpty then inj1 () else inj2 (), 
%    	#2 (exists1 (a,())), 
%    	#2 (exists1 (b,())), 
%    	#2 (exists1 (c,()))
%    )
%  )
%
%datatype _ = EmptyS | ConsS of _
%fun exists2 ((l,s), p) =
%  case unroll p of 
%    inj1 () => false
%  | inj2 (anyEmpty,p_a,p_b,p_c) => 
%      case s of
%        EmptyS => 
%          case anyEmpty of 
%            inj1 () => true 
%          | inj2 () => false
%      | ConsS (z,zs) =>
%          case z of
%            A => exists2 (((),zs),p_a)
%          | B => exists2 (((),zs),p_b)
%          | C => exists2 (((),zs),p_c)
%\end{lstlisting}
%
%As promised, this split version creates a trie in stage \bbone, and consumes it in stage \bbtwo.
%Note that we made the same simplification in the {\tt partition} function here as in the quickselect example.
%As far as how stage splitting compares to partial evaluation, it's again the same story as above:
%partial evaluation embeds the whole trie into the residual as an if nest, 
%whereas splitting efficiently represents the trie as a value.
%
%\subsection{Analysis}
%
%For practical purposes there are three primary differences between stage splitting and partial evaluation.
%
%Firstly, partial evaluation embeds the intermediate data structure into the code of the residual, whereas
%stage-splitting more efficiently realizes the data structure as a value.  This saves, potentially massively, on memory.
%
%Secondly, partial evaluation will eliminate first-stage branches it knows it doesn't need to take,
%whereas stage-splitting will keep them around.  
%To see exactly where this phenomenon happens, compare the evaluation and splitting rules for stage \bbone\ if-statements.
%This is generally a win for partial evaluation.
%
%Finally, stage-splitting can be performed without knowing the first-stage value,
%which can be the difference between compile-time and run-time.
%Since running a partial evaluator might be prohibitively expensive at run-time, this is a large win for stage-splitting.
%
%\section{Discussion}
%
%In this section, I'll discuss the appropriateness of \lang\ (and the stage-splitting transformation) for the stated application of algorithm derivation, and I will also speculate on potential other applications. This section is intended to be more frank.
%
%\subsection{Feasibility of Staging for Algorithm Derivation}
%
%The big question from our previous section is whether its feasible to write algorithms using staging.  
%
%After some practice, I can say that the staging and typing rules of \lang\ are fairly natural, 
%and writing correct programs is not mind-bendingly difficult, even when speculation is involved.
%Certainly, the programmer will have to have some knowledge of what sort of data structure she's going for,
%but all programming requires forethought.
%
%Once the program is written, the benefits are obvious.
%Using \lang\ and generating two mono-stage functions using splitting cuts code size by roughly half (over writting the split code directly),
%and it's certainly easier to reason about and prove algorithm correctness when the intermediate data structure is implicit.
%
%One major limiting factor is application scope.  
%The only practical examples that we've been able to conjure, including quickselect and trie generation, 
%all fit into the model of turning divide-and-conquer search into a tree build-and-search algorithm.  
%It's a good start, but we've been largely unable to find applicability beyond code of this structure.
%In particular, we definitely can not derive data structures like auto-balancing trees, 
%because that would require explicit access to the structure, which we don't have (the structure is implicit in the \lang\ code).
%Hopefully, there are some classes of algorithms that we just haven't thought of, so we're open to suggestions.
%
%\subsection {Applications to DSLs}
%
%They may be potential applications to domain specific languages which deploy to multi-processor systems, 
%though this is largely conjecture.
%In general it is interesting to consider situations that can be modeled by \lang\, and then determine if splitting is a meaningful operation in that context.
%
%\subsubsection{Shading Languages: e.g., Spark}
%
%Shading languages are one example, 
%where \lang\ stages could be put in correspondence with those of the graphics pipeline.
%Of course, this would require generalizing \lang's simple two-stage model to finite DAGs of stages.
%In such a case, splitting turns a "pipeline program" (using Foley's term) into a one-shader-per-stage output that is required by current graphics systems.
%The closest work to this would be Spark (\cite{Foley:2011}), which performs essentially this
%operation, but for an input language with fewer features (notably, no first-class functions), 
%and a simpler staging model that rules out behavior like speculation.
%
%Interestingly, Spark's staging restrictions are sufficient to ensure 
%that the precomputation is always a base value or tuple, and never an injection 
%(which we allow via stage \bbone\ {\tt if}/{\tt case}).
%The result is that Spark can guarantee a well-defined merging operator for all precomputations, 
%which it leverages to combine the results from {\em multiple stage-\bbone\ invocations} to a single stage-\bbtwo\ invocation
%(and in generality, many-to-many communication between invocations).
%Lacking such a well-defined operator, \lang\ can only model a one-to-many stage invocation pattern.
%
%Spark uses this capabilty to support resampling of values between stages (for instance, a color @vertex is merged into color @fragment), 
%where the merging operator is interpolation of multiple \bbone\ values.  
%To get similar behavior in \lang, we'd either need to restrict the input language
%or find a way to generalize interpolation to sum types.
%
%\subsubsection{Functional Reactive Programming}
%
%Last, I've seen some applications of a type system like that of \lang\ to functional reactive programming (\cite{cave14}).
%They use partial evaluation as a semantics,
%and I have a hunch that stage splitting could be better.
%This would require closing that gap between their type system and ours, which would require generalization to
%an infinite chain of stages.
