

\section{Examples of Algorithm Derivation}
\label{sec:examples}

We have observed that stage splitting can be used to transform \lang\ programs into two step algorithms where the precomputation generates a data-structure, and the residual uses the precomputed structure to accelerate repeated computation.  Three examples of this behavior follow: the fast exponent example from Section~\ref{sec:stagedsemantics}, a derivation of the quickselect algorithm, and the use of splitting to generate a structure resembling a trie.
 
We urge the reader to pay attention to how partial evaluation (essentially \lang's dynamic semantics) and execution of the outputs of stage splitting compare for these examples.
The main difference to note is that where splitting creates an explicit data structure, partial evaluation will
essentially embed that datastructure in the residual. 

\subsection{Fast Exponent}

Here is a staged version of the fast-exponent example from before.
\begin{lstlisting} 
fun fexp (b : $int, e : int) : $int =
	if e == 0 then
		next{1}
	else if (e mod 2) == 0 then
		next{let x = prev{fexp(b,e/2)} in x*x}
	else
		next{prev{b} * prev{fexp (b,e-1)}}		
\end{lstlisting}
It splits into
\begin{lstlisting} 
fun fexp (b, e) =
  ((), roll (
    if e == 0 then inj1 ()
    else
      inj2 (
        if (e mod 2) == 0
        then inj1 (#2 (fexp (b,e/2)))
        else inj2 (#2 (fexp (b,e-1)))
      )
  ))
\end{lstlisting}
and
\begin{lstlisting} 
fun fexp ((b, e), p) =
	case unroll p of
	  inj1 () => 1
	| inj2 d =>
		case d of
		  inj1 r => let x = fexp ((b,()),r) in x*x
		| inj2 r => b * fexp ((b,()),r)
\end{lstlisting}

Although split programs are not typed, we'll recognize the intermediate data structure 
above as being as isomorphic to the recursive datatype definitions:
\begin{lstlisting} 
datatype binaryList = Empty 
                      | NotEmpty of neList
withtype neList = Zero of binaryList 
                  | One of binaryList
\end{lstlisting}
Which is all to say that the split code precomputes a binary representation of the exponent.
Since integers are usually stored in a binary format anyways, this isn't practically useful,
but it's still an interesting exposition of the technique.

Partially evaluating the code here might actually be useful, since the residual wouldn't have branches,
and exponents tend to be small enough that the code size would be reasonable.

\subsection{Quickselect}

Here we have a staged version of the quickselect algorithm.
Standard quickselect finds the $i$th largest number in a list by recursively partitioning the list by its 
first element and picking the side which contains the $i$th largest element.
In this case, we've staged quickselect by saying that the list is stage \bbone\ and $i$ is stage \bbtwo.
Note that the helper function {\tt partition} operates entirely in stage \bbone.

\begin{lstlisting} 
datatype list = Empty | Cons of int * list
fun partition ((p,l) : int*list) : (int*list*list) =
  case unroll l of 
    Empty => (0,Empty, Empty) 
  | Cons (h,t) =>
      let (s,left,right) = partition (p,t) in
      if h<p 
      then (s+1,Cons(h,left),right)
      else (s,left,Cons(h,right))
fun qs (l : list, i: $int) = 
  case l of
    Empty => next {0}
  | Cons (h,t) => 
      let (left,right,n) = partition h t in
      next{
        let n = hold{n} in
          case compare prev{i} n of
            LT => prev {qs left i}
          | EQ => hold {h}
          | GT => prev {qs right next{prev{i}-n-1}}
      }	
\end{lstlisting}
Running our stage splitting algorithm on this code produces something like:
\begin{lstlisting} 
datatype _ = Empty | Cons of _
fun partition (p,l) =
  case unroll l of 
    Empty => (0,Empty, Empty) 
  | Cons (h,t) =>
      let (s,left,right) = partition (p,t) in
      if h<p 
      then (s+1,Cons(h,left),right)
      else (s,left,Cons(h,right))
fun qs (l, i) = roll((), 
  case l of
    Empty => inj1 ()
  | Cons (h,t) => 
      inj2 (
        let (left,right,n) = partition h t in
        (n, #2 (qs left i), h, #2 (qs right i))
      )
  )
\end{lstlisting}
and 
\begin{lstlisting} 
fun qs ((l, i), p) = 
  case unroll p of
    inj1 () => 0
  | inj2 (n,p1,h,p2) => 
      case compare prev{i} n of
        LT => qs () i
      | EQ => h
      | GT => qs () (i-n-1)
\end{lstlisting}
In English, these functions just recursively build and then search a binary tree,
which stores a set element and subtree size at every branch.

Note that we've made a few simplifications in rendering this output:
\begin{itemize}
\item Outputs are untyped.  Rather than elaborate out the datatypes, we keep them in and just null out the types.
\item The partition function doesn't have any real stage two computation,
but that won't stop the current algorithm from keeping track of all the recursive calls in partition 
and then retracing all of its steps in stage-\bbtwo, only to produce a unit value at the end.  
That's massively inefficient, and we elided it here.
\end{itemize}

Modulo the points I just made, splitting does a good job here.  
Partial evaluation creates a giant tree of if statements proportional to the size of the list,
whereas splitting just creates the tree out of values, and then interprets it in the residual.
For large input lists (which is typical), this saves a lot on memory.

\subsection{Trie}

Our last example is one which generates a trie intermediate data structure.

The problem is determining whether a query string (from the alphabet $\{A, B,C\}$) occurs in a given set.
We solve this by partitioning the initial set into three subsets,
one which contains all the words that start with $A$,
one which contains all the words that start with $B$, and one likewise for $C$.
When partitioning, we also throw away the first letter, since we know it's uniform for the whole subset.
Also while doing this partitioning, we also keep track of whether the empty word occurred at all.
We then look at the query string.  If it's empty, we return whether the empty word was in the set.
Otherwise, we look at the first letter, pick the appropriate subset, 
and recursively search for the rest of our query string in that.

We stage this algorithm by saying that the word set comes at stage \bbone\
and the query string comes at stage \bbtwo.

\begin{lstlisting} 
datatype letter = A | B | C
datatype string = EmptyS | ConsS of letter * string
datatype list = EmptyL | ConsL of string * list
fun partition (l : list) : (bool * list * list * list) =
  case l of
    EmptyL => (false,EmptyL,EmptyL,EmptyL)
  | ConsL (s,ss) =>
      let (anyEmpty,a,b,c) = partition ss in
      case unroll s of
        EmptyS => (true,a,b,c)
      | ConsS (z,zs) =>
          case z of 
            A => (anyEmpty, ConsL(zs,a), b, c) 
          | B => (anyEmpty, a, ConsL(zs,b), c) 
          | C => (anyEmpty, a, b, ConsL(zs, c))
fun exists ((l,s) : list * $string) : $bool =
  case l of 
    EmptyL => next{false} 
  | ConsL _ => 
    let (anyEmpty, a, b, c) = partition l in
    next {
      case prev{s} of
        EmptyS => prev{
          if anyEmpty then next{true} else next{false}
          }
      | ConsS (z,zs) =>
          case z of
            A => prev{exists (a,next{zs})}
          | B => prev{exists (b,next{zs})} 
          | C => prev{exists (c,next{zs})}
    }
\end{lstlisting}
Running the splitting algorithm on this produces:

\begin{lstlisting} 
datatype _ = EmptyS | ConsS of _
datatype _ = EmptyL | ConsL of _
fun partition l =
  case l of
    EmptyL => (false,EmptyL,EmptyL,EmptyL)
  | ConsL (s,ss) =>
      let (anyEmpty,a,b,c) = partition ss in
      case unroll s of
        EmptyS => (true,a,b,c)
      | ConsS (z,zs) =>
          case z of 
            A => (anyEmpty, ConsL(zs,a), b, c) 
          | B => (anyEmpty, a, ConsL(zs,b), c) 
          | C => (anyEmpty, a, b, ConsL(zs, c))
fun exists (l,s) = roll ((), 
  case l of 
    EmptyL => inj1 ()
  | ConsL _ => 
    let (anyEmpty, a, b, c) = partition l in
    inj2 (
    	if anyEmpty then inj1 () else inj2 (), 
    	#2 (exists (a,())), 
    	#2 (exists (b,())), 
    	#2 (exists (c,()))
    )
  )
\end{lstlisting}
and 
\begin{lstlisting} 
datatype _ = EmptyS | ConsS of _
fun exists ((l,s), p) =
  case unroll p of 
    inj1 () => false
  | inj2 (anyEmpty,p_a,p_b,p_c) => 
      case s of
        EmptyS => 
          case anyEmpty of 
            inj1 () => true 
          | inj2 () => false
      | ConsS (z,zs) =>
          case z of
            A => exists (((),zs),p_a)
          | B => exists (((),zs),p_b)
          | C => exists (((),zs),p_c)
\end{lstlisting}

As promised, this split version creates a trie in stage \bbone, and consumes it in stage \bbtwo.
Note that we made the same simplification in the {\tt partition} function here as in the quickselect example.
As far as how stage splitting compares to partial evaluation, it's again the same story as above:
partial evaluation embeds the whole trie into the residual as an if nest, 
whereas quickselect efficiently represents the trie as a value.

\subsection{Analysis}

For practical purposes there are three primary differences between stage splitting and partial evaluation.

Firstly, partial evaluation embeds the intermediate data structure into the code of the residual, whereas
stage-splitting more efficiently realizes the data structure as a value.  This saves, potentially massively, on memory.

Secondly, partial evaluation will eliminate first-stage branches it knows it doesn't need to take,
whereas stage-splitting will keep them around.  
To see exactly where this phenomenon happens, compare the evaluation and splitting rules for stage \bbone\ if-statements.
This is generally a win for partial evaluation.

Finally, stage-splitting can be performed without knowing the first-stage value,
which can be the difference between compile-time and run-time.
Since running a partial evaluator might be prohibitively expensive at run-time, this is a large win for stage-splitting.

\section{Conclusions and Future Work}

In this section, I'll discuss how appropriate \lang\ and stage-splitting are for stated application and others.  
This section is intended to be more frank.

\subsection{Feasibility of Staging for Algorithm Derivation}

The big question from our previous section is whether its feasible to write algorithms using staging.  

After some practice, I can say that the staging and typing rules of \lang are fairly natural, 
and writing correct programs is not mind-bendingly difficult, even when speculation is involved.
Certainly, the programmer will have to have some knowledge of what sort of data structure she's going for,
but all programming requires forethought.

And once the program is written, the benefits are obvious.
Using \lang\ and splitting cuts code size by roughly half,
and it's certainly way easier to reason about and prove correctness when the intermediate data structure is implicit.

If there is a limiting factor, it would be scope.  
The only practical examples that we've been able to conjure, including the quickselect and trie, 
all fit into the model of turning divide-and-conquer search into a tree build-and-search algorithm.  
It's a good start, but we've been largely unable to go beyond that formula.

In particular, we definitely can't derive any data structures like auto-balancing trees, 
because that would require explicit access to the structure, which we don't have.
Hopefully, there are some classes of algorithms that we just haven't thought of, so we're open to suggestions.

\subsection {Applications to DSLs}

There are also many potential applications to domain specific languages which deploy to multi-processor systems, 
though this line of research is largely at the conjectural stage.
For the most part, my method is finding situations that \lang\ can model, and then hoping that splitting means something in context.

\subsubsection{Spark}

One example of this is shading languages,
where we identify our stages with those of the graphics pipeline.
This would require generalizing our staging model from two stages to any finite DAG.
In such a case, splitting turns an ubershader into one shader per stage.
The closest work to this would be Spark (\cite{Foley:2011}), which does essentially this
but for an input language with fewer features (notably, no first-class functions), 
and a simpler staging model that rules out behavior like speculation.

Interestingly enough, Spark's staging restrictions are sufficient to ensure 
that the precomputation is always a base value or tuple, and never an injection 
(which we allow via stage \bbone\ {\tt if}/{\tt case}).
This means that Spark can guarantee a defined merging operator for all precomputations, 
which it then leverages to combine the results from multiple stage-\bbone\ invocations to a single stage-\bbtwo\ invocation
(and in generality, many-to-many).
Lacking such a well-defined operator, we're stuck only modeling a one-to-many stage invocation pattern.

Spark uses this strength to do resampling (for instance, a color @vertex is merged into color @fragment), 
whering the merging operator is some sort of interpolation.  
If we wanted that behavior, then we'd either have to restrict the input language
or find a way to generalize interpolation to sum types.

\subsubsection{Liszt}

We may be able to target stenciling languages such as Liszt.  
Essentially, the stencil itself is identified with the stage graph, 
and so stencil locality is enforced by the type system.
It's not immediately clear what stage splitting maps to here, but my bet is it has something to do with phases.


\subsubsection{Functional Reactive Programming}

The last option is functional reactive programming.
I've seen some applications of a type system like that of \lang\ to FRP (cite in a bit),
and they use partial evaluation as a semantics.
I have a hunch that stage splitting could be better.