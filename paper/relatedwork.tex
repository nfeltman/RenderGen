
\section{Related Work}

\subsection {Staged Computation}
Partial evaluation is a well-studied technique for specializing programs to some of their input.  
The usual phrasing of the partial evaluation problem implicitly includes binding time analysis,
but many presentations start with a stage-annotated representation, as we have done.
We've shown that our dynamic semantics can be used to perform partial evaluation 
[need to do more reading to know exactly how it compares].

One unifying feature of partial evaluation systems is that they operate on code which is closed at the first stage,
and so they must necessarily unfold recursive calls.
This potentially explodes the size of a residual, which can be a problem.
Stage-splitting, in contrast, operates on terms which are open on first stage variables,
and so this problem is avoided.

There's another staging technique known as {\em metaprogramming} (\cite{taha-thesis-99}, \cite{devito13}, \cite{davies01}).
The differences between it and partial evaluation can be subtle.
The core idea of metaprogramming is to interpret stage \bbtwo\ values as {\em code} in some object language
which stage \bbone\ can manipulate.
This has three implications:
\begin{itemize}
\item Stage annotations are now mandatory, rather than optional.
\item The $\next$-contents-duplicating semantics is now intended behavior [this needs to be verified].
This changes the cost of terms from what they would be in \lang's semantics, 
but that's merely something for the programmer to keep in mind.
\item In metaprogramming systems, it now makes sense to define an operator, \texttt{run}, 
which evaluates stage \bbtwo\ code to get an answer back at stage \bbone.
When you think about it, this is a form a backwards information flow.
For this reason, the \texttt{run} feature is in direct conflict with stage-splitting,
which by its definition cannot work for a language that allows backwards control flow.
\end{itemize}

\subsection{Stage Splitting}

Stage-splitting itself has appeared in the literature---under 
the names {\em pass separation} and {\em data specialization}--- for various simpler input languages.

Most often, splitting is considered a compiler optimization (\cite{jorring86},\cite{knoblock96})
to minimize recomputation.
In this use case, only the arguments to the program are annotated with stages, 
and the splitter is left to perform an {\em ad hoc} binding time analysis to determine the 
internal staging of the program.
Because this occurs without programmer supervision, the binding time analyzers for these uses are 
reluctant to place stage \bbone\ code within stage \bbtwo\ conditionals, 
since that would result in speculative behavior that could increase the overall runtime.
We don't worry about this since the annotations of \lang\ are assumed to represent the will of a programmer.

Like the previous example, the Spark language (\cite{sparkThesis}) uses staging to minimize recomputation in real-time rendering applications.  
But instead of using a binding-time analysis to determine what parts of the program to put in what shader, 
Spark gives the programmer manual control of term staging using a language that is in spirit similar to \lang. 

We are also not the first to use stage splitting to derive algorithms.
\cite{malmkjaer89}, expanding on the work of \cite{barzdins88}, defined a stage-splitter
for a language of tail-recursive first-order equations with explicit staging annotations [double check that],
and considered applications to string matching.

Our work is distinct from all previous stage splitters in the following ways:
\begin{itemize}
\item Our input language, \lang, has a disciplined type theory.
\item \lang\ has full first-class functions (and by extension, recursion), as well as sum types.
\item Our stage splitting is proven correct.
\end{itemize}

\subsection{Davies}

\cite{davies96} explored the connection between linear temporal logic and its corresponding type system (which is nearly identical to that for \lang), 
and showed the equivalence between that type system and existing one for binding time analysis. 
That work also provided a metaprogramming-style duplicating dynamic semantics, which we purposely avoided.
That said, the dynamics of \cite{davies96} is otherwise very similar to ours.
In fact, if we change the $\next$ and $\prev$ rules of ours to 
\begin{mathpar}
\infer {\diaone {\next~e}{\cdot,\next~q}} {\diatwo e q} \and
\infer {\diatwo{\prev~e}{v}} {\diaone e {\cdot,\next~v}} 
\end{mathpar}
and treat $\next~q$ as a partial value for any residual $q$,
then our semantics becomes rule-for-rule isomorphic to that from \cite{davies96}. This essentially bypasses the
environment bookkeeping in $\redonesym$, by inlining residuals instead of
hoisting them in \verb|let|-bindings.
From this it's clear that the semantics of \cite{davies96} and ours always produce the same value when they both terminate.
{\em However because \lang's semantics dictate that a reified residual will always be evaluated, regardless of whether its result is consumed, \lang\ programs terminate strictly less often than that of \cite{davies96}}.

