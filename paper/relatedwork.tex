


\section{Related Work}


\subsection{Davies}

\cite{davies96} explored the connection between linear temporal logic and its corresponding type system (which is nearly identical to that for \lang), 
and showed the equivalence between that type system and existing one for binding time analysis. 
That work also provided a metaprogramming-style duplicating dynamic semantics, which we purposely avoided.
That said, the dynamics of \cite{davies96} is otherwise very similar to ours.
In fact, if we change the $\next$ and $\prev$ rules of ours to 
\begin{mathpar}
\infer {\diaone {\next~e}{\cdot,\next~q}} {\diatwo e q} \and
\infer {\diatwo{\prev~e}{v}} {\diaone e {\cdot,\next~v}} 
\end{mathpar}
and treat $\next~q$ as a partial value for any residual $q$,
then our semantics becomes rule-for-rule isomorphic to that from \cite{davies96}. This essentially bypasses the
environment bookkeeping in $\redonesym$, by inlining residuals instead of
hoisting them in \verb|let|-bindings.
From this it's clear that the semantics of \cite{davies96} and ours always produce the same value when they both terminate.
{\em However because \lang's semantics dictate that a reified residual will always be evaluated, regardless of whether its result is consumed, \lang\ programs terminate strictly less often than that of \cite{davies96}}.

\subsection{Multi-stage (meta) programming}
{\bf Umut: jotting down notes for now.}

Multi-stage, a.k.a., meta programming or staged programming, gives the
programmer linguistic facilities consisting of language constructs
(usually also a type system, including a dynamic semantics) for
expressing programs where inputs may come in stages.  Earlier work on
staged programming was motivated by understanding the effects of
binding-time analysis that partial evaluation relied on and allowing
control over staging so that the programmer can control the
termination and efficiency characteristics of staged programs.
Several different approaches to staged programming has been proposed.


Davies ...  

Taha's approach is similar to Davies, but extends Davies's approach
with ``cross-stage persistency'' which allows a variable to be used in
any later stage and a ``run'' construct that allows evaluating an
expression.  Our language constructs therefore are also close to
staged programming such as proposed by Taha.  In fact our static
semantics is essentially identical to Taha's.  Though, as Davies, we
don't include ``run'' in the language.  The dynamic semantics of
staged languages... COMPLETE


The key difference between our work and Taha's and similar work on
staging is our splitting algorithm that can translate the staged code
to a different code that can run significantly (sometimes
asymptotically) faster. COMPARE DYNAMIC SEMANTICS

 Unlike the evaluati




\subsection{Specialization}

Our stage-splitting algorithm was first suggested in \cite{jorring86} under the name {\em pass separation}.  They essentially proposed that a function $f$ could be split into two others, $f_1$ and $f_2$, such that $f(x,y)=f_2(f_1(x),y)$.  They did not distinguish binding time analysis from stage splitting, and so pass separation inherits the former's ambiguity.  The main goal of \cite{jorring86} was to motivate pass separation and other staging transformations as a powerful way to think about compilation and optimization.  Accordingly, their approach was entirely informal, with no implementation realized.  Moreover, they predicted that ``the [pass separation] approach will elude full automation for some time."  

Implementations of the stage-splitting algorithm have appeared in the literature exclusively (and coincidentally) in the context of graphics pipelines.  The first of these (\cite{knoblock96}) uses a binding time analysis to separate those parts of graphics shaders that are input-invariant from those which are not, and then uses a stage splitting algorithm to factor that into two shaders, thereby minimizing recomputation.  Their shaders are written in a C-like language with basic arithmetic and if statements.  Although their analysis does not give an explicit account of the type-level behavior of the splitting algorithm, it effectively can synthesize product and sum boundary type.  

\subsection{Graphics Systems}

Like the previous example, the Spark language (\cite{sparkThesis}) uses staging to minimize recomputation in real-time rendering applications.  But instead of using a binding-time analysis, Spark allows the programmer to manually target stages of the graphics pipeline.  Since the modern graphics pipeline is inherently a many-to-one system, this is difficult to reconcile with sum types on the boundary.  Fortunately, Spark has a set of syntactic restrictions that prevent sum boundary types.  Spark does not clearly identify this conflict, but the authors did note that first-stage if statements were difficult to provide meaning to [need quote].

[RTSL and SH]


